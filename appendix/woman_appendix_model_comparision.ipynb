{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_df(rating,clothes,user):\n",
    "    df = pd.merge(rating,user,how='inner',on='R_id')\n",
    "    df = pd.merge(df,clothes,how='inner',on='image')\n",
    "    df=df.drop(columns=['스타일선호','mar','job','income','r_style1','r_style2','r_style3','r_style4','r_style5'])\n",
    "    df_rating = df['선호여부']\n",
    "    df = df.drop(columns=['선호여부'])\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    #print(df.head())\n",
    "    df_encoded = encoder.fit_transform(df.loc[:,'r_gender':'분위기'])\n",
    "    \n",
    "    df_encoded = pd.DataFrame(df_encoded,columns= [f\"col{i}_{elem}\" for i,sublist in enumerate(encoder.categories_) for elem in sublist])\n",
    "    #df = pd.concat([df[['R_id','image']],df_encoded,df.loc[:,'멋있다':].astype(np.int8)],axis=1)\n",
    "    df = pd.concat([df_encoded,df.loc[:,'멋있다':]],axis=1)\n",
    "    #df = df_encoded\n",
    "\n",
    "    return df,df_rating,encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_df(rating,clothes,user,encoder):\n",
    "    df = pd.merge(rating,user,how='inner',on='R_id')\n",
    "    df = pd.merge(df,clothes,how='inner',on='image')\n",
    "    \n",
    "    df=df.drop(columns=['스타일선호','mar','job','income','r_style1','r_style2','r_style3','r_style4','r_style5'])\n",
    "    df_rating = df['선호여부']\n",
    "    df = df.drop(columns=['선호여부'])\n",
    "    df_encoded = encoder.transform(df.loc[:,'r_gender':'분위기'])\n",
    "    df_encoded = pd.DataFrame(df_encoded,columns= [f\"col{i}_{elem}\" for i,sublist in enumerate(encoder.categories_) for elem in sublist])\n",
    "    #df = pd.concat([df[['R_id','image']],df_encoded,df.loc[:,'멋있다':].astype(np.int8)],axis=1)\n",
    "    df = pd.concat([df_encoded,df.loc[:,'멋있다':]],axis=1)\n",
    "    #df = df_encoded\n",
    "    return df,df_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('../preprocessed/TL_woman_rating_2019.csv')\n",
    "clothes = pd.read_csv('../preprocessed/TL_woman_clothes_2019.csv',index_col='image')\n",
    "user = pd.read_csv('../preprocessed/TL_woman_user_2019.csv',index_col='R_id')\n",
    "\n",
    "train_x,train_y,encoder = make_train_df(rating,clothes,user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.to_csv('../train/train_x_woman.csv',index=False)\n",
    "train_y.to_csv('../train/train_y_woman.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../encoder/onehot_encoder_woman.pkl','wb') as f:\n",
    "    pickle.dump(encoder,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('../preprocessed/VL_woman_rating_2019.csv')\n",
    "clothes = pd.read_csv('../preprocessed/VL_woman_clothes_2019.csv',index_col='image')\n",
    "user = pd.read_csv('../preprocessed/VL_woman_user_2019.csv',index_col='R_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,test_y = make_test_df(rating,clothes,user,encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_binary(value):\n",
    "    if value<3.0:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(rating_,predict_value,k):\n",
    "    rating_df = pd.read_csv(rating_)\n",
    "    predict_df = pd.DataFrame({'예측': predict_value})\n",
    "    rating_df = pd.concat([rating_df,predict_df],axis=1)\n",
    "\n",
    "    precisions = []\n",
    "\n",
    "    for user in rating_df['R_id'].unique():\n",
    "        if len(rating_df[rating_df['R_id']==user])>=2:\n",
    "            pred = rating_df.loc[rating_df['R_id'] == user,['image','선호여부','예측']].sort_values(by='예측',ascending=False).reset_index(drop=True)\n",
    "            pred_k = pred.head(k)\n",
    "            precision = len(pred_k.loc[pred_k['선호여부']>=3.0]) / float(k)\n",
    "            precisions.append(precision)\n",
    "                \n",
    "    return sum(precisions) / len(precisions)\n",
    "\n",
    "\n",
    "def recall_at_k(rating_,predict_value,k):\n",
    "    rating_df = pd.read_csv(rating_)\n",
    "    \n",
    "    predict_df = pd.DataFrame({'예측': predict_value})\n",
    " \n",
    "    rating_df = pd.concat([rating_df,predict_df],axis=1)\n",
    "    recalls = []\n",
    "\n",
    "  \n",
    "    for user in rating_df['R_id'].unique():\n",
    "        if len(rating_df[rating_df['R_id']==user])>=2:\n",
    "            pred = rating_df.loc[rating_df['R_id']==user,['image','선호여부','예측']].sort_values(by='예측',ascending=False).reset_index(drop=True)\n",
    "            pred_k = pred.head(k)\n",
    "            recall = len(pred_k.loc[pred_k['선호여부']>=3.0]) / len(pred.loc[pred['선호여부']>=3.0]) if len(pred.loc[pred['선호여부']>=3.0])>0 else 0\n",
    "            recalls.append(recall)\n",
    "\n",
    "    return sum(recalls) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k_by_personal(rating_,user_,predict_value,k):\n",
    "    rating_df = pd.read_csv(rating_)\n",
    "    user_df = pd.read_csv(user_)\n",
    "    predict_df = pd.DataFrame({'예측': predict_value})\n",
    "    rating_df = rating_df.merge(user_df,how='inner',on='R_id')\n",
    "    rating_df = pd.concat([rating_df,predict_df],axis=1)\n",
    "\n",
    "    precisions = []\n",
    "\n",
    "    for color in rating_df['personal_color'].unique():\n",
    "        for face in rating_df['faceshape'].unique():\n",
    "            for body in rating_df['bodyshape'].unique():\n",
    "\n",
    "                pred = rating_df.loc[(rating_df['personal_color']==color) & (rating_df['faceshape']==face) & (rating_df['bodyshape']==body),['image','선호여부','예측']].sort_values(by='예측',ascending=False).reset_index(drop=True)\n",
    "                pred_k =pred.head(k)\n",
    "                if len(pred_k)>0:\n",
    "                    precision = len(pred_k.loc[pred_k['선호여부']>=3.0]) / float(k)\n",
    "                    precisions.append(precision)\n",
    "\n",
    "    return sum(precisions) / len(precisions)\n",
    "\n",
    "\n",
    "def recall_at_k_by_personal(rating_,user_,predict_value,k):\n",
    "    rating_df = pd.read_csv(rating_)\n",
    "    user_df = pd.read_csv(user_)\n",
    "    predict_df = pd.DataFrame({'예측': predict_value})\n",
    "    rating_df = rating_df.merge(user_df,how='inner',on='R_id')\n",
    "    rating_df = pd.concat([rating_df,predict_df],axis=1)\n",
    "    recalls = []\n",
    "\n",
    "    for color in rating_df['personal_color'].unique():\n",
    "        for face in rating_df['faceshape'].unique():\n",
    "            for body in rating_df['bodyshape'].unique():\n",
    "\n",
    "                pred = rating_df.loc[(rating_df['personal_color']==color) & (rating_df['faceshape']==face) & (rating_df['bodyshape']==body),['image','선호여부','예측']].sort_values(by='예측',ascending=False).reset_index(drop=True)\n",
    "                pred_k = pred.head(k)\n",
    "                if len(pred_k)>0:\n",
    "                    recall = len(pred_k.loc[pred_k['선호여부']>=3.0]) / len(pred.loc[pred['선호여부']>=3.0]) if len(pred.loc[pred['선호여부']>=3.0])>0 else 0\n",
    "                    recalls.append(recall)\n",
    "\n",
    "    return sum(recalls) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "def test_model(reg):\n",
    "    \n",
    "    train_predict = reg.predict(train_x)\n",
    "    print(\"Train RMSE:{}\".format(math.sqrt(mean_squared_error(train_predict, train_y))) )\n",
    "    test_predict = reg.predict(test_x)\n",
    "    print(\"RMSE':{}\".format(math.sqrt(mean_squared_error(test_predict, test_y))) )\n",
    "\n",
    "    \n",
    "\n",
    "    train_predict_binary = np.vectorize(map_to_binary)(train_predict)\n",
    "    train_y_binary = np.vectorize(map_to_binary)(train_y)\n",
    "    test_predict_binary = np.vectorize(map_to_binary)(test_predict)\n",
    "    test_y_binary = np.vectorize(map_to_binary)(test_y)\n",
    "    print(\"train classification report\")\n",
    "    print(classification_report(train_y_binary,train_predict_binary))\n",
    "    print(\"test classification report\")\n",
    "    print(classification_report(test_y_binary,test_predict_binary))\n",
    "    k=10\n",
    "    print(f\"precision@{k} of train: \",precision_at_k('../preprocessed/TL_woman_rating_2019.csv',train_predict,k))\n",
    "    print(f\"recall@10 of train: \",recall_at_k('../preprocessed/TL_woman_rating_2019.csv',train_predict,k))\n",
    "    \n",
    "    print(f\"precision@{k} of test: \",precision_at_k('../preprocessed/VL_woman_rating_2019.csv',test_predict,k))\n",
    "    print(f\"recall@{k} of test: \",recall_at_k('../preprocessed/VL_woman_rating_2019.csv',test_predict,k))\n",
    "\n",
    "    print(\"PERSONAL PRECISION RECALL\")\n",
    "    k=10\n",
    "    print(f\"precision@{k} of train\" , precision_at_k_by_personal('../preprocessed/TL_woman_rating_2019.csv','../preprocessed/TL_woman_user_2019.csv',train_predict,k))\n",
    "    print(f\"recall@{k} of train\" , recall_at_k_by_personal('../preprocessed/TL_woman_rating_2019.csv','../preprocessed/TL_woman_user_2019.csv',train_predict,k))\n",
    "    print(f\"precision@{k} of test: \",precision_at_k_by_personal('../preprocessed/VL_woman_rating_2019.csv','../preprocessed/VL_woman_user_2019.csv',test_predict,k))\n",
    "    print(f\"recall@{k} of test: \",recall_at_k_by_personal('../preprocessed/VL_woman_rating_2019.csv','../preprocessed/VL_woman_user_2019.csv',test_predict,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"XGBoost\": xgb.XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=6,\n",
    "        subsample=0.8, colsample_bytree=0.8, gamma=0,\n",
    "        reg_alpha=0.1, reg_lambda=1, random_state=0\n",
    "    ),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, num_leaves=31,\n",
    "        max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_alpha=0.1, reg_lambda=1, random_state=0\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=5,\n",
    "        min_samples_split=5, min_samples_leaf=2, subsample=0.8,\n",
    "        random_state=0\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=300, max_depth=10, min_samples_split=5,\n",
    "        min_samples_leaf=2, random_state=0\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostRegressor(\n",
    "        iterations=500, learning_rate=0.05, depth=6,\n",
    "        l2_leaf_reg=1, verbose=0,subsample=0.8,random_state=0\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Evaluating XGBoost model...\n",
      "Train RMSE:0.635439859114642\n",
      "RMSE':0.7734359416458834\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70      7516\n",
      "           1       0.96      0.37      0.54     10027\n",
      "\n",
      "    accuracy                           0.63     17543\n",
      "   macro avg       0.75      0.68      0.62     17543\n",
      "weighted avg       0.78      0.63      0.61     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.92      0.64      1033\n",
      "           1       0.84      0.29      0.43      1405\n",
      "\n",
      "    accuracy                           0.56      2438\n",
      "   macro avg       0.66      0.61      0.54      2438\n",
      "weighted avg       0.69      0.56      0.52      2438\n",
      "\n",
      "precision@10 of train:  0.3504745166959577\n",
      "recall@10 of train:  0.9483883411216687\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9387755102040817\n",
      "recall@10 of train 0.32997823035261936\n",
      "precision@10 of test:  0.6069767441860465\n",
      "recall@10 of test:  0.6294372874247169\n",
      "Training LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 114\n",
      "[LightGBM] [Info] Number of data points in the train set: 17543, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 2.561421\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Evaluating LightGBM model...\n",
      "Train RMSE:0.7029167616448968\n",
      "RMSE':0.7707314803635837\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.97      0.68      7516\n",
      "           1       0.93      0.33      0.49     10027\n",
      "\n",
      "    accuracy                           0.61     17543\n",
      "   macro avg       0.73      0.65      0.58     17543\n",
      "weighted avg       0.76      0.61      0.57     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.93      0.64      1033\n",
      "           1       0.84      0.27      0.41      1405\n",
      "\n",
      "    accuracy                           0.55      2438\n",
      "   macro avg       0.66      0.60      0.52      2438\n",
      "weighted avg       0.69      0.55      0.51      2438\n",
      "\n",
      "precision@10 of train:  0.3502987697715289\n",
      "recall@10 of train:  0.9482378790902519\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9122448979591836\n",
      "recall@10 of train 0.3212953486503106\n",
      "precision@10 of test:  0.6023255813953488\n",
      "recall@10 of test:  0.6249280475565978\n",
      "Training GradientBoosting model...\n",
      "Evaluating GradientBoosting model...\n",
      "Train RMSE:0.7191510654546782\n",
      "RMSE':0.7692372332881237\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67      7516\n",
      "           1       0.92      0.32      0.48     10027\n",
      "\n",
      "    accuracy                           0.60     17543\n",
      "   macro avg       0.72      0.64      0.57     17543\n",
      "weighted avg       0.75      0.60      0.56     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.64      1033\n",
      "           1       0.86      0.26      0.40      1405\n",
      "\n",
      "    accuracy                           0.55      2438\n",
      "   macro avg       0.67      0.60      0.52      2438\n",
      "weighted avg       0.70      0.55      0.50      2438\n",
      "\n",
      "precision@10 of train:  0.3502636203866431\n",
      "recall@10 of train:  0.9482034911819394\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9142857142857143\n",
      "recall@10 of train 0.32136531562797177\n",
      "precision@10 of test:  0.6046511627906976\n",
      "recall@10 of test:  0.6219843497714058\n",
      "Training RandomForest model...\n",
      "Evaluating RandomForest model...\n",
      "Train RMSE:0.7216032417244338\n",
      "RMSE':0.7729595575342963\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67      7516\n",
      "           1       0.95      0.28      0.44     10027\n",
      "\n",
      "    accuracy                           0.58     17543\n",
      "   macro avg       0.73      0.63      0.55     17543\n",
      "weighted avg       0.76      0.58      0.53     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63      1033\n",
      "           1       0.87      0.22      0.35      1405\n",
      "\n",
      "    accuracy                           0.53      2438\n",
      "   macro avg       0.67      0.59      0.49      2438\n",
      "weighted avg       0.70      0.53      0.47      2438\n",
      "\n",
      "precision@10 of train:  0.3501581722319858\n",
      "recall@10 of train:  0.9480535356892771\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9040816326530611\n",
      "recall@10 of train 0.3141907781760047\n",
      "precision@10 of test:  0.6093023255813954\n",
      "recall@10 of test:  0.6236971519708508\n",
      "Training CatBoost model...\n",
      "Evaluating CatBoost model...\n",
      "Train RMSE:0.7189891479962761\n",
      "RMSE':0.7673370454212468\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.96      0.67      7516\n",
      "           1       0.92      0.31      0.46     10027\n",
      "\n",
      "    accuracy                           0.59     17543\n",
      "   macro avg       0.72      0.64      0.57     17543\n",
      "weighted avg       0.75      0.59      0.55     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.64      1033\n",
      "           1       0.86      0.26      0.40      1405\n",
      "\n",
      "    accuracy                           0.55      2438\n",
      "   macro avg       0.67      0.60      0.52      2438\n",
      "weighted avg       0.70      0.55      0.50      2438\n",
      "\n",
      "precision@10 of train:  0.3502987697715289\n",
      "recall@10 of train:  0.948206368909357\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9163265306122447\n",
      "recall@10 of train 0.32103547602103866\n",
      "precision@10 of test:  0.6139534883720931\n",
      "recall@10 of test:  0.6297885692444756\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    model.fit(train_x, train_y)\n",
    "    print(f\"Evaluating {model_name} model...\")\n",
    "    test_model(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"XGBoost\": xgb.XGBRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, max_depth=6,\n",
    "        subsample=0.8, colsample_bytree=0.8, gamma=0,\n",
    "        reg_alpha=0.1, reg_lambda=1, random_state=0\n",
    "    ),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, num_leaves=31,\n",
    "        max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_alpha=0.1, reg_lambda=1, random_state=0\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, max_depth=5,\n",
    "        min_samples_split=5, min_samples_leaf=2, subsample=0.8,\n",
    "        random_state=0\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=1000, max_depth=10, min_samples_split=5,\n",
    "        min_samples_leaf=2, random_state=0\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostRegressor(\n",
    "        iterations=1000, learning_rate=0.05, depth=6,\n",
    "        l2_leaf_reg=1, subsample=0.8, verbose=0,random_state=0\n",
    "    ),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(\n",
    "        max_depth=10, min_samples_split=5, min_samples_leaf=2,\n",
    "        random_state=0\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Evaluating XGBoost model...\n",
      "Train RMSE:0.5589698172254809\n",
      "RMSE':0.7848611027435858\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.72      7516\n",
      "           1       0.98      0.42      0.59     10027\n",
      "\n",
      "    accuracy                           0.66     17543\n",
      "   macro avg       0.77      0.70      0.65     17543\n",
      "weighted avg       0.80      0.66      0.64     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.91      0.64      1033\n",
      "           1       0.83      0.31      0.45      1405\n",
      "\n",
      "    accuracy                           0.57      2438\n",
      "   macro avg       0.66      0.61      0.55      2438\n",
      "weighted avg       0.69      0.57      0.53      2438\n",
      "\n",
      "precision@10 of train:  0.3506151142355007\n",
      "recall@10 of train:  0.9484215377629497\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9489795918367347\n",
      "recall@10 of train 0.3330247996296809\n",
      "precision@10 of test:  0.6139534883720931\n",
      "recall@10 of test:  0.6310713917151191\n",
      "Training LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 114\n",
      "[LightGBM] [Info] Number of data points in the train set: 17543, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 2.561421\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Evaluating LightGBM model...\n",
      "Train RMSE:0.6587789907893766\n",
      "RMSE':0.7747008997256739\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69      7516\n",
      "           1       0.95      0.37      0.53     10027\n",
      "\n",
      "    accuracy                           0.63     17543\n",
      "   macro avg       0.74      0.67      0.61     17543\n",
      "weighted avg       0.77      0.63      0.60     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.92      0.64      1033\n",
      "           1       0.84      0.29      0.44      1405\n",
      "\n",
      "    accuracy                           0.56      2438\n",
      "   macro avg       0.67      0.61      0.54      2438\n",
      "weighted avg       0.69      0.56      0.52      2438\n",
      "\n",
      "precision@10 of train:  0.35040421792618615\n",
      "recall@10 of train:  0.9483198943216522\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9346938775510204\n",
      "recall@10 of train 0.3274272099444561\n",
      "precision@10 of test:  0.6046511627906976\n",
      "recall@10 of test:  0.6248989405985996\n",
      "Training GradientBoosting model...\n",
      "Evaluating GradientBoosting model...\n",
      "Train RMSE:0.641263993561533\n",
      "RMSE':0.7794578517911016\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.70      7516\n",
      "           1       0.95      0.38      0.54     10027\n",
      "\n",
      "    accuracy                           0.63     17543\n",
      "   macro avg       0.75      0.68      0.62     17543\n",
      "weighted avg       0.78      0.63      0.61     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64      1033\n",
      "           1       0.85      0.30      0.44      1405\n",
      "\n",
      "    accuracy                           0.56      2438\n",
      "   macro avg       0.67      0.61      0.54      2438\n",
      "weighted avg       0.70      0.56      0.53      2438\n",
      "\n",
      "precision@10 of train:  0.3505448154657292\n",
      "recall@10 of train:  0.94853150071955\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9387755102040817\n",
      "recall@10 of train 0.3297033440633273\n",
      "precision@10 of test:  0.6116279069767442\n",
      "recall@10 of test:  0.6301966957822834\n",
      "Training RandomForest model...\n",
      "Evaluating RandomForest model...\n",
      "Train RMSE:0.7211670954389988\n",
      "RMSE':0.7733331893232255\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67      7516\n",
      "           1       0.95      0.28      0.43     10027\n",
      "\n",
      "    accuracy                           0.58     17543\n",
      "   macro avg       0.73      0.63      0.55     17543\n",
      "weighted avg       0.76      0.58      0.53     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63      1033\n",
      "           1       0.87      0.22      0.35      1405\n",
      "\n",
      "    accuracy                           0.53      2438\n",
      "   macro avg       0.67      0.59      0.49      2438\n",
      "weighted avg       0.70      0.53      0.47      2438\n",
      "\n",
      "precision@10 of train:  0.3501230228471\n",
      "recall@10 of train:  0.9479832369195056\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9081632653061223\n",
      "recall@10 of train 0.31606152647532443\n",
      "precision@10 of test:  0.6139534883720932\n",
      "recall@10 of test:  0.6269619104681675\n",
      "Training CatBoost model...\n",
      "Evaluating CatBoost model...\n",
      "Train RMSE:0.6719972837501207\n",
      "RMSE':0.7707748243549453\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.68      7516\n",
      "           1       0.95      0.35      0.51     10027\n",
      "\n",
      "    accuracy                           0.62     17543\n",
      "   macro avg       0.74      0.66      0.60     17543\n",
      "weighted avg       0.77      0.62      0.58     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64      1033\n",
      "           1       0.85      0.28      0.43      1405\n",
      "\n",
      "    accuracy                           0.56      2438\n",
      "   macro avg       0.67      0.61      0.53      2438\n",
      "weighted avg       0.70      0.56      0.52      2438\n",
      "\n",
      "precision@10 of train:  0.3503690685413004\n",
      "recall@10 of train:  0.9482844786535475\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.930612244897959\n",
      "recall@10 of train 0.32685356778918123\n",
      "precision@10 of test:  0.6116279069767442\n",
      "recall@10 of test:  0.6324347684432459\n",
      "Training DecisionTree model...\n",
      "Evaluating DecisionTree model...\n",
      "Train RMSE:0.7516787152803431\n",
      "RMSE':0.8228399427653961\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.66      7516\n",
      "           1       0.89      0.32      0.47     10027\n",
      "\n",
      "    accuracy                           0.59     17543\n",
      "   macro avg       0.70      0.63      0.56     17543\n",
      "weighted avg       0.73      0.59      0.55     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.63      1033\n",
      "           1       0.81      0.24      0.37      1405\n",
      "\n",
      "    accuracy                           0.53      2438\n",
      "   macro avg       0.64      0.58      0.50      2438\n",
      "weighted avg       0.67      0.53      0.48      2438\n",
      "\n",
      "precision@10 of train:  0.34959578207381364\n",
      "recall@10 of train:  0.9473000251272381\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.8612244897959183\n",
      "recall@10 of train 0.2992065665850187\n",
      "precision@10 of test:  0.5627906976744187\n",
      "recall@10 of test:  0.6007383835932872\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    model.fit(train_x, train_y)\n",
    "    print(f\"Evaluating {model_name} model...\")\n",
    "    test_model(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"XGBoost\": xgb.XGBRegressor(\n",
    "         random_state=0\n",
    "    ),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(\n",
    "        random_state=0\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "       \n",
    "        random_state=0\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "         random_state=0\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostRegressor(\n",
    "        random_state=0\n",
    "    ),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(\n",
    "        random_state=0\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Evaluating XGBoost model...\n",
      "Train RMSE:0.6212227577693992\n",
      "RMSE':0.7958271000811171\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70      7516\n",
      "           1       0.96      0.40      0.56     10027\n",
      "\n",
      "    accuracy                           0.65     17543\n",
      "   macro avg       0.75      0.69      0.63     17543\n",
      "weighted avg       0.78      0.65      0.62     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.91      0.64      1033\n",
      "           1       0.84      0.32      0.47      1405\n",
      "\n",
      "    accuracy                           0.57      2438\n",
      "   macro avg       0.67      0.62      0.55      2438\n",
      "weighted avg       0.69      0.57      0.54      2438\n",
      "\n",
      "precision@10 of train:  0.35057996485061493\n",
      "recall@10 of train:  0.9485754374506572\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9489795918367347\n",
      "recall@10 of train 0.33286918182700426\n",
      "precision@10 of test:  0.6\n",
      "recall@10 of test:  0.6228854669594268\n",
      "Training LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 114\n",
      "[LightGBM] [Info] Number of data points in the train set: 17543, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 2.561421\n",
      "Evaluating LightGBM model...\n",
      "Train RMSE:0.7339032208135555\n",
      "RMSE':0.7687140821733199\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.96      0.67      7516\n",
      "           1       0.92      0.31      0.46     10027\n",
      "\n",
      "    accuracy                           0.59     17543\n",
      "   macro avg       0.71      0.63      0.56     17543\n",
      "weighted avg       0.74      0.59      0.55     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.95      0.64      1033\n",
      "           1       0.87      0.26      0.40      1405\n",
      "\n",
      "    accuracy                           0.55      2438\n",
      "   macro avg       0.68      0.60      0.52      2438\n",
      "weighted avg       0.71      0.55      0.50      2438\n",
      "\n",
      "precision@10 of train:  0.35012302284710006\n",
      "recall@10 of train:  0.9480282595748327\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.8979591836734693\n",
      "recall@10 of train 0.3161012682613352\n",
      "precision@10 of test:  0.6069767441860464\n",
      "recall@10 of test:  0.62419822935181\n",
      "Training GradientBoosting model...\n",
      "Evaluating GradientBoosting model...\n",
      "Train RMSE:0.7781568090224458\n",
      "RMSE':0.7702663703941237\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.96      0.65      7516\n",
      "           1       0.88      0.25      0.38     10027\n",
      "\n",
      "    accuracy                           0.55     17543\n",
      "   macro avg       0.69      0.60      0.52     17543\n",
      "weighted avg       0.71      0.55      0.50     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63      1033\n",
      "           1       0.88      0.21      0.34      1405\n",
      "\n",
      "    accuracy                           0.53      2438\n",
      "   macro avg       0.67      0.59      0.49      2438\n",
      "weighted avg       0.70      0.53      0.46      2438\n",
      "\n",
      "precision@10 of train:  0.3499472759226712\n",
      "recall@10 of train:  0.9477762288482853\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.83469387755102\n",
      "recall@10 of train 0.29843531639862697\n",
      "precision@10 of test:  0.6\n",
      "recall@10 of test:  0.6213203652098644\n",
      "Training RandomForest model...\n",
      "Evaluating RandomForest model...\n",
      "Train RMSE:0.3136099496099953\n",
      "RMSE':0.7729973117505007\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      7516\n",
      "           1       1.00      0.46      0.63     10027\n",
      "\n",
      "    accuracy                           0.69     17543\n",
      "   macro avg       0.79      0.73      0.68     17543\n",
      "weighted avg       0.82      0.69      0.67     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.65      1033\n",
      "           1       0.86      0.30      0.44      1405\n",
      "\n",
      "    accuracy                           0.57      2438\n",
      "   macro avg       0.67      0.61      0.54      2438\n",
      "weighted avg       0.70      0.57      0.53      2438\n",
      "\n",
      "precision@10 of train:  0.35100175746924417\n",
      "recall@10 of train:  0.9489748742916815\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9510204081632654\n",
      "recall@10 of train 0.33362503972571933\n",
      "precision@10 of test:  0.6069767441860466\n",
      "recall@10 of test:  0.6221385899471726\n",
      "Training CatBoost model...\n",
      "Learning rate set to 0.06438\n",
      "0:\tlearn: 0.9088227\ttotal: 3.57ms\tremaining: 3.56s\n",
      "1:\tlearn: 0.8980982\ttotal: 7.12ms\tremaining: 3.55s\n",
      "2:\tlearn: 0.8884567\ttotal: 10.7ms\tremaining: 3.57s\n",
      "3:\tlearn: 0.8796704\ttotal: 14.3ms\tremaining: 3.55s\n",
      "4:\tlearn: 0.8724607\ttotal: 17.8ms\tremaining: 3.55s\n",
      "5:\tlearn: 0.8657335\ttotal: 21.3ms\tremaining: 3.53s\n",
      "6:\tlearn: 0.8594931\ttotal: 24.8ms\tremaining: 3.52s\n",
      "7:\tlearn: 0.8538457\ttotal: 28.4ms\tremaining: 3.52s\n",
      "8:\tlearn: 0.8484799\ttotal: 31.9ms\tremaining: 3.51s\n",
      "9:\tlearn: 0.8439991\ttotal: 35.2ms\tremaining: 3.49s\n",
      "10:\tlearn: 0.8395855\ttotal: 38.7ms\tremaining: 3.48s\n",
      "11:\tlearn: 0.8361089\ttotal: 42.3ms\tremaining: 3.48s\n",
      "12:\tlearn: 0.8327125\ttotal: 45.8ms\tremaining: 3.48s\n",
      "13:\tlearn: 0.8297738\ttotal: 49.4ms\tremaining: 3.48s\n",
      "14:\tlearn: 0.8270355\ttotal: 52.9ms\tremaining: 3.47s\n",
      "15:\tlearn: 0.8244838\ttotal: 56.4ms\tremaining: 3.47s\n",
      "16:\tlearn: 0.8219551\ttotal: 60ms\tremaining: 3.47s\n",
      "17:\tlearn: 0.8195880\ttotal: 63.5ms\tremaining: 3.46s\n",
      "18:\tlearn: 0.8174768\ttotal: 66.9ms\tremaining: 3.45s\n",
      "19:\tlearn: 0.8156790\ttotal: 70.4ms\tremaining: 3.45s\n",
      "20:\tlearn: 0.8137510\ttotal: 73.9ms\tremaining: 3.44s\n",
      "21:\tlearn: 0.8120287\ttotal: 77.3ms\tremaining: 3.44s\n",
      "22:\tlearn: 0.8104449\ttotal: 80.9ms\tremaining: 3.44s\n",
      "23:\tlearn: 0.8088215\ttotal: 84.5ms\tremaining: 3.44s\n",
      "24:\tlearn: 0.8074750\ttotal: 88ms\tremaining: 3.43s\n",
      "25:\tlearn: 0.8062497\ttotal: 91.5ms\tremaining: 3.43s\n",
      "26:\tlearn: 0.8050464\ttotal: 95ms\tremaining: 3.42s\n",
      "27:\tlearn: 0.8039806\ttotal: 98.4ms\tremaining: 3.41s\n",
      "28:\tlearn: 0.8027734\ttotal: 102ms\tremaining: 3.41s\n",
      "29:\tlearn: 0.8019658\ttotal: 105ms\tremaining: 3.4s\n",
      "30:\tlearn: 0.8009371\ttotal: 109ms\tremaining: 3.4s\n",
      "31:\tlearn: 0.7997556\ttotal: 112ms\tremaining: 3.4s\n",
      "32:\tlearn: 0.7987062\ttotal: 116ms\tremaining: 3.39s\n",
      "33:\tlearn: 0.7977707\ttotal: 119ms\tremaining: 3.39s\n",
      "34:\tlearn: 0.7969450\ttotal: 122ms\tremaining: 3.38s\n",
      "35:\tlearn: 0.7962448\ttotal: 126ms\tremaining: 3.38s\n",
      "36:\tlearn: 0.7955386\ttotal: 130ms\tremaining: 3.37s\n",
      "37:\tlearn: 0.7947650\ttotal: 133ms\tremaining: 3.37s\n",
      "38:\tlearn: 0.7941449\ttotal: 137ms\tremaining: 3.37s\n",
      "39:\tlearn: 0.7934736\ttotal: 140ms\tremaining: 3.36s\n",
      "40:\tlearn: 0.7928456\ttotal: 144ms\tremaining: 3.36s\n",
      "41:\tlearn: 0.7922465\ttotal: 147ms\tremaining: 3.35s\n",
      "42:\tlearn: 0.7917708\ttotal: 151ms\tremaining: 3.35s\n",
      "43:\tlearn: 0.7911044\ttotal: 154ms\tremaining: 3.35s\n",
      "44:\tlearn: 0.7905284\ttotal: 158ms\tremaining: 3.35s\n",
      "45:\tlearn: 0.7900101\ttotal: 161ms\tremaining: 3.34s\n",
      "46:\tlearn: 0.7894492\ttotal: 165ms\tremaining: 3.34s\n",
      "47:\tlearn: 0.7889337\ttotal: 168ms\tremaining: 3.33s\n",
      "48:\tlearn: 0.7884806\ttotal: 172ms\tremaining: 3.33s\n",
      "49:\tlearn: 0.7879199\ttotal: 175ms\tremaining: 3.33s\n",
      "50:\tlearn: 0.7874383\ttotal: 179ms\tremaining: 3.32s\n",
      "51:\tlearn: 0.7869303\ttotal: 182ms\tremaining: 3.32s\n",
      "52:\tlearn: 0.7865433\ttotal: 186ms\tremaining: 3.32s\n",
      "53:\tlearn: 0.7861308\ttotal: 190ms\tremaining: 3.32s\n",
      "54:\tlearn: 0.7857497\ttotal: 193ms\tremaining: 3.32s\n",
      "55:\tlearn: 0.7854441\ttotal: 197ms\tremaining: 3.31s\n",
      "56:\tlearn: 0.7851230\ttotal: 200ms\tremaining: 3.31s\n",
      "57:\tlearn: 0.7847001\ttotal: 204ms\tremaining: 3.31s\n",
      "58:\tlearn: 0.7843744\ttotal: 207ms\tremaining: 3.31s\n",
      "59:\tlearn: 0.7839944\ttotal: 211ms\tremaining: 3.31s\n",
      "60:\tlearn: 0.7836219\ttotal: 214ms\tremaining: 3.3s\n",
      "61:\tlearn: 0.7833430\ttotal: 218ms\tremaining: 3.3s\n",
      "62:\tlearn: 0.7829731\ttotal: 221ms\tremaining: 3.29s\n",
      "63:\tlearn: 0.7826653\ttotal: 225ms\tremaining: 3.29s\n",
      "64:\tlearn: 0.7823602\ttotal: 228ms\tremaining: 3.29s\n",
      "65:\tlearn: 0.7820602\ttotal: 232ms\tremaining: 3.29s\n",
      "66:\tlearn: 0.7817192\ttotal: 236ms\tremaining: 3.28s\n",
      "67:\tlearn: 0.7814647\ttotal: 239ms\tremaining: 3.28s\n",
      "68:\tlearn: 0.7811405\ttotal: 243ms\tremaining: 3.27s\n",
      "69:\tlearn: 0.7809023\ttotal: 246ms\tremaining: 3.27s\n",
      "70:\tlearn: 0.7805557\ttotal: 250ms\tremaining: 3.27s\n",
      "71:\tlearn: 0.7802867\ttotal: 253ms\tremaining: 3.26s\n",
      "72:\tlearn: 0.7799457\ttotal: 257ms\tremaining: 3.26s\n",
      "73:\tlearn: 0.7796679\ttotal: 260ms\tremaining: 3.25s\n",
      "74:\tlearn: 0.7793980\ttotal: 264ms\tremaining: 3.25s\n",
      "75:\tlearn: 0.7790165\ttotal: 267ms\tremaining: 3.25s\n",
      "76:\tlearn: 0.7787142\ttotal: 271ms\tremaining: 3.25s\n",
      "77:\tlearn: 0.7784509\ttotal: 274ms\tremaining: 3.24s\n",
      "78:\tlearn: 0.7781449\ttotal: 278ms\tremaining: 3.24s\n",
      "79:\tlearn: 0.7778579\ttotal: 281ms\tremaining: 3.23s\n",
      "80:\tlearn: 0.7775686\ttotal: 285ms\tremaining: 3.23s\n",
      "81:\tlearn: 0.7773522\ttotal: 288ms\tremaining: 3.23s\n",
      "82:\tlearn: 0.7770425\ttotal: 292ms\tremaining: 3.22s\n",
      "83:\tlearn: 0.7768511\ttotal: 295ms\tremaining: 3.22s\n",
      "84:\tlearn: 0.7765676\ttotal: 299ms\tremaining: 3.21s\n",
      "85:\tlearn: 0.7763024\ttotal: 302ms\tremaining: 3.21s\n",
      "86:\tlearn: 0.7760540\ttotal: 307ms\tremaining: 3.22s\n",
      "87:\tlearn: 0.7757855\ttotal: 310ms\tremaining: 3.22s\n",
      "88:\tlearn: 0.7754781\ttotal: 314ms\tremaining: 3.21s\n",
      "89:\tlearn: 0.7751208\ttotal: 318ms\tremaining: 3.21s\n",
      "90:\tlearn: 0.7749475\ttotal: 321ms\tremaining: 3.21s\n",
      "91:\tlearn: 0.7747416\ttotal: 325ms\tremaining: 3.21s\n",
      "92:\tlearn: 0.7745454\ttotal: 329ms\tremaining: 3.2s\n",
      "93:\tlearn: 0.7743329\ttotal: 332ms\tremaining: 3.2s\n",
      "94:\tlearn: 0.7742003\ttotal: 336ms\tremaining: 3.2s\n",
      "95:\tlearn: 0.7740167\ttotal: 339ms\tremaining: 3.19s\n",
      "96:\tlearn: 0.7737745\ttotal: 343ms\tremaining: 3.19s\n",
      "97:\tlearn: 0.7736046\ttotal: 346ms\tremaining: 3.19s\n",
      "98:\tlearn: 0.7734210\ttotal: 350ms\tremaining: 3.18s\n",
      "99:\tlearn: 0.7732252\ttotal: 353ms\tremaining: 3.18s\n",
      "100:\tlearn: 0.7730095\ttotal: 357ms\tremaining: 3.18s\n",
      "101:\tlearn: 0.7726637\ttotal: 361ms\tremaining: 3.18s\n",
      "102:\tlearn: 0.7724677\ttotal: 365ms\tremaining: 3.18s\n",
      "103:\tlearn: 0.7722422\ttotal: 368ms\tremaining: 3.17s\n",
      "104:\tlearn: 0.7720154\ttotal: 372ms\tremaining: 3.17s\n",
      "105:\tlearn: 0.7717619\ttotal: 375ms\tremaining: 3.17s\n",
      "106:\tlearn: 0.7716333\ttotal: 379ms\tremaining: 3.16s\n",
      "107:\tlearn: 0.7714231\ttotal: 382ms\tremaining: 3.16s\n",
      "108:\tlearn: 0.7711444\ttotal: 386ms\tremaining: 3.15s\n",
      "109:\tlearn: 0.7709373\ttotal: 390ms\tremaining: 3.15s\n",
      "110:\tlearn: 0.7707603\ttotal: 393ms\tremaining: 3.15s\n",
      "111:\tlearn: 0.7705130\ttotal: 397ms\tremaining: 3.15s\n",
      "112:\tlearn: 0.7702467\ttotal: 401ms\tremaining: 3.15s\n",
      "113:\tlearn: 0.7699680\ttotal: 405ms\tremaining: 3.14s\n",
      "114:\tlearn: 0.7697210\ttotal: 408ms\tremaining: 3.14s\n",
      "115:\tlearn: 0.7695257\ttotal: 412ms\tremaining: 3.14s\n",
      "116:\tlearn: 0.7693275\ttotal: 416ms\tremaining: 3.14s\n",
      "117:\tlearn: 0.7691690\ttotal: 419ms\tremaining: 3.13s\n",
      "118:\tlearn: 0.7689630\ttotal: 423ms\tremaining: 3.13s\n",
      "119:\tlearn: 0.7687896\ttotal: 426ms\tremaining: 3.13s\n",
      "120:\tlearn: 0.7685558\ttotal: 430ms\tremaining: 3.12s\n",
      "121:\tlearn: 0.7683943\ttotal: 434ms\tremaining: 3.12s\n",
      "122:\tlearn: 0.7682344\ttotal: 437ms\tremaining: 3.12s\n",
      "123:\tlearn: 0.7680499\ttotal: 441ms\tremaining: 3.12s\n",
      "124:\tlearn: 0.7678099\ttotal: 445ms\tremaining: 3.11s\n",
      "125:\tlearn: 0.7676221\ttotal: 448ms\tremaining: 3.11s\n",
      "126:\tlearn: 0.7673886\ttotal: 452ms\tremaining: 3.11s\n",
      "127:\tlearn: 0.7671017\ttotal: 456ms\tremaining: 3.11s\n",
      "128:\tlearn: 0.7669426\ttotal: 460ms\tremaining: 3.1s\n",
      "129:\tlearn: 0.7667595\ttotal: 463ms\tremaining: 3.1s\n",
      "130:\tlearn: 0.7665728\ttotal: 467ms\tremaining: 3.1s\n",
      "131:\tlearn: 0.7664165\ttotal: 470ms\tremaining: 3.09s\n",
      "132:\tlearn: 0.7662452\ttotal: 474ms\tremaining: 3.09s\n",
      "133:\tlearn: 0.7660263\ttotal: 477ms\tremaining: 3.08s\n",
      "134:\tlearn: 0.7657596\ttotal: 481ms\tremaining: 3.08s\n",
      "135:\tlearn: 0.7655700\ttotal: 485ms\tremaining: 3.08s\n",
      "136:\tlearn: 0.7653320\ttotal: 488ms\tremaining: 3.08s\n",
      "137:\tlearn: 0.7651871\ttotal: 492ms\tremaining: 3.08s\n",
      "138:\tlearn: 0.7649215\ttotal: 496ms\tremaining: 3.07s\n",
      "139:\tlearn: 0.7647495\ttotal: 500ms\tremaining: 3.07s\n",
      "140:\tlearn: 0.7645406\ttotal: 504ms\tremaining: 3.07s\n",
      "141:\tlearn: 0.7643123\ttotal: 508ms\tremaining: 3.07s\n",
      "142:\tlearn: 0.7640806\ttotal: 511ms\tremaining: 3.06s\n",
      "143:\tlearn: 0.7638420\ttotal: 515ms\tremaining: 3.06s\n",
      "144:\tlearn: 0.7636058\ttotal: 518ms\tremaining: 3.06s\n",
      "145:\tlearn: 0.7633929\ttotal: 522ms\tremaining: 3.05s\n",
      "146:\tlearn: 0.7632153\ttotal: 526ms\tremaining: 3.05s\n",
      "147:\tlearn: 0.7629781\ttotal: 529ms\tremaining: 3.05s\n",
      "148:\tlearn: 0.7628156\ttotal: 533ms\tremaining: 3.04s\n",
      "149:\tlearn: 0.7626349\ttotal: 536ms\tremaining: 3.04s\n",
      "150:\tlearn: 0.7623760\ttotal: 540ms\tremaining: 3.04s\n",
      "151:\tlearn: 0.7622601\ttotal: 543ms\tremaining: 3.03s\n",
      "152:\tlearn: 0.7621427\ttotal: 547ms\tremaining: 3.03s\n",
      "153:\tlearn: 0.7618909\ttotal: 550ms\tremaining: 3.02s\n",
      "154:\tlearn: 0.7616064\ttotal: 554ms\tremaining: 3.02s\n",
      "155:\tlearn: 0.7614680\ttotal: 558ms\tremaining: 3.02s\n",
      "156:\tlearn: 0.7612641\ttotal: 562ms\tremaining: 3.01s\n",
      "157:\tlearn: 0.7610392\ttotal: 565ms\tremaining: 3.01s\n",
      "158:\tlearn: 0.7608419\ttotal: 569ms\tremaining: 3.01s\n",
      "159:\tlearn: 0.7606872\ttotal: 572ms\tremaining: 3s\n",
      "160:\tlearn: 0.7604650\ttotal: 576ms\tremaining: 3s\n",
      "161:\tlearn: 0.7602128\ttotal: 579ms\tremaining: 3s\n",
      "162:\tlearn: 0.7600412\ttotal: 583ms\tremaining: 2.99s\n",
      "163:\tlearn: 0.7598610\ttotal: 586ms\tremaining: 2.99s\n",
      "164:\tlearn: 0.7596830\ttotal: 590ms\tremaining: 2.99s\n",
      "165:\tlearn: 0.7594944\ttotal: 594ms\tremaining: 2.98s\n",
      "166:\tlearn: 0.7593339\ttotal: 598ms\tremaining: 2.98s\n",
      "167:\tlearn: 0.7591841\ttotal: 602ms\tremaining: 2.98s\n",
      "168:\tlearn: 0.7590112\ttotal: 605ms\tremaining: 2.98s\n",
      "169:\tlearn: 0.7588712\ttotal: 609ms\tremaining: 2.97s\n",
      "170:\tlearn: 0.7586903\ttotal: 613ms\tremaining: 2.97s\n",
      "171:\tlearn: 0.7584828\ttotal: 617ms\tremaining: 2.97s\n",
      "172:\tlearn: 0.7582756\ttotal: 621ms\tremaining: 2.97s\n",
      "173:\tlearn: 0.7581527\ttotal: 625ms\tremaining: 2.96s\n",
      "174:\tlearn: 0.7579497\ttotal: 628ms\tremaining: 2.96s\n",
      "175:\tlearn: 0.7577569\ttotal: 632ms\tremaining: 2.96s\n",
      "176:\tlearn: 0.7575532\ttotal: 636ms\tremaining: 2.96s\n",
      "177:\tlearn: 0.7573277\ttotal: 640ms\tremaining: 2.95s\n",
      "178:\tlearn: 0.7571630\ttotal: 643ms\tremaining: 2.95s\n",
      "179:\tlearn: 0.7569723\ttotal: 647ms\tremaining: 2.95s\n",
      "180:\tlearn: 0.7567759\ttotal: 651ms\tremaining: 2.94s\n",
      "181:\tlearn: 0.7565755\ttotal: 654ms\tremaining: 2.94s\n",
      "182:\tlearn: 0.7564226\ttotal: 658ms\tremaining: 2.94s\n",
      "183:\tlearn: 0.7561534\ttotal: 661ms\tremaining: 2.93s\n",
      "184:\tlearn: 0.7559747\ttotal: 665ms\tremaining: 2.93s\n",
      "185:\tlearn: 0.7557585\ttotal: 669ms\tremaining: 2.93s\n",
      "186:\tlearn: 0.7555743\ttotal: 672ms\tremaining: 2.92s\n",
      "187:\tlearn: 0.7554086\ttotal: 676ms\tremaining: 2.92s\n",
      "188:\tlearn: 0.7552379\ttotal: 679ms\tremaining: 2.91s\n",
      "189:\tlearn: 0.7551028\ttotal: 683ms\tremaining: 2.91s\n",
      "190:\tlearn: 0.7549461\ttotal: 687ms\tremaining: 2.91s\n",
      "191:\tlearn: 0.7547631\ttotal: 690ms\tremaining: 2.9s\n",
      "192:\tlearn: 0.7545979\ttotal: 694ms\tremaining: 2.9s\n",
      "193:\tlearn: 0.7544061\ttotal: 698ms\tremaining: 2.9s\n",
      "194:\tlearn: 0.7542444\ttotal: 701ms\tremaining: 2.9s\n",
      "195:\tlearn: 0.7540955\ttotal: 705ms\tremaining: 2.89s\n",
      "196:\tlearn: 0.7539191\ttotal: 709ms\tremaining: 2.89s\n",
      "197:\tlearn: 0.7537902\ttotal: 713ms\tremaining: 2.89s\n",
      "198:\tlearn: 0.7536435\ttotal: 717ms\tremaining: 2.88s\n",
      "199:\tlearn: 0.7534511\ttotal: 720ms\tremaining: 2.88s\n",
      "200:\tlearn: 0.7533489\ttotal: 724ms\tremaining: 2.88s\n",
      "201:\tlearn: 0.7531158\ttotal: 728ms\tremaining: 2.88s\n",
      "202:\tlearn: 0.7529188\ttotal: 732ms\tremaining: 2.87s\n",
      "203:\tlearn: 0.7527819\ttotal: 735ms\tremaining: 2.87s\n",
      "204:\tlearn: 0.7525997\ttotal: 739ms\tremaining: 2.87s\n",
      "205:\tlearn: 0.7524488\ttotal: 743ms\tremaining: 2.86s\n",
      "206:\tlearn: 0.7522878\ttotal: 746ms\tremaining: 2.86s\n",
      "207:\tlearn: 0.7521268\ttotal: 750ms\tremaining: 2.86s\n",
      "208:\tlearn: 0.7519620\ttotal: 754ms\tremaining: 2.85s\n",
      "209:\tlearn: 0.7517179\ttotal: 758ms\tremaining: 2.85s\n",
      "210:\tlearn: 0.7515109\ttotal: 761ms\tremaining: 2.85s\n",
      "211:\tlearn: 0.7513539\ttotal: 766ms\tremaining: 2.85s\n",
      "212:\tlearn: 0.7512413\ttotal: 770ms\tremaining: 2.84s\n",
      "213:\tlearn: 0.7510543\ttotal: 775ms\tremaining: 2.85s\n",
      "214:\tlearn: 0.7509301\ttotal: 779ms\tremaining: 2.84s\n",
      "215:\tlearn: 0.7507798\ttotal: 782ms\tremaining: 2.84s\n",
      "216:\tlearn: 0.7506456\ttotal: 786ms\tremaining: 2.84s\n",
      "217:\tlearn: 0.7504507\ttotal: 790ms\tremaining: 2.83s\n",
      "218:\tlearn: 0.7502555\ttotal: 793ms\tremaining: 2.83s\n",
      "219:\tlearn: 0.7500397\ttotal: 797ms\tremaining: 2.83s\n",
      "220:\tlearn: 0.7498446\ttotal: 801ms\tremaining: 2.82s\n",
      "221:\tlearn: 0.7496275\ttotal: 804ms\tremaining: 2.82s\n",
      "222:\tlearn: 0.7493774\ttotal: 809ms\tremaining: 2.82s\n",
      "223:\tlearn: 0.7491701\ttotal: 812ms\tremaining: 2.81s\n",
      "224:\tlearn: 0.7489958\ttotal: 816ms\tremaining: 2.81s\n",
      "225:\tlearn: 0.7488015\ttotal: 820ms\tremaining: 2.81s\n",
      "226:\tlearn: 0.7486076\ttotal: 824ms\tremaining: 2.8s\n",
      "227:\tlearn: 0.7484707\ttotal: 827ms\tremaining: 2.8s\n",
      "228:\tlearn: 0.7482960\ttotal: 831ms\tremaining: 2.8s\n",
      "229:\tlearn: 0.7480613\ttotal: 834ms\tremaining: 2.79s\n",
      "230:\tlearn: 0.7478703\ttotal: 838ms\tremaining: 2.79s\n",
      "231:\tlearn: 0.7477711\ttotal: 842ms\tremaining: 2.79s\n",
      "232:\tlearn: 0.7475861\ttotal: 845ms\tremaining: 2.78s\n",
      "233:\tlearn: 0.7474034\ttotal: 849ms\tremaining: 2.78s\n",
      "234:\tlearn: 0.7472981\ttotal: 852ms\tremaining: 2.77s\n",
      "235:\tlearn: 0.7471108\ttotal: 856ms\tremaining: 2.77s\n",
      "236:\tlearn: 0.7468957\ttotal: 859ms\tremaining: 2.77s\n",
      "237:\tlearn: 0.7467485\ttotal: 863ms\tremaining: 2.76s\n",
      "238:\tlearn: 0.7465447\ttotal: 866ms\tremaining: 2.76s\n",
      "239:\tlearn: 0.7464032\ttotal: 870ms\tremaining: 2.76s\n",
      "240:\tlearn: 0.7462934\ttotal: 875ms\tremaining: 2.75s\n",
      "241:\tlearn: 0.7461594\ttotal: 879ms\tremaining: 2.75s\n",
      "242:\tlearn: 0.7459914\ttotal: 883ms\tremaining: 2.75s\n",
      "243:\tlearn: 0.7457684\ttotal: 886ms\tremaining: 2.75s\n",
      "244:\tlearn: 0.7456008\ttotal: 890ms\tremaining: 2.74s\n",
      "245:\tlearn: 0.7454673\ttotal: 894ms\tremaining: 2.74s\n",
      "246:\tlearn: 0.7453153\ttotal: 897ms\tremaining: 2.73s\n",
      "247:\tlearn: 0.7450852\ttotal: 901ms\tremaining: 2.73s\n",
      "248:\tlearn: 0.7449322\ttotal: 905ms\tremaining: 2.73s\n",
      "249:\tlearn: 0.7447333\ttotal: 909ms\tremaining: 2.73s\n",
      "250:\tlearn: 0.7446229\ttotal: 912ms\tremaining: 2.72s\n",
      "251:\tlearn: 0.7444771\ttotal: 916ms\tremaining: 2.72s\n",
      "252:\tlearn: 0.7443175\ttotal: 920ms\tremaining: 2.72s\n",
      "253:\tlearn: 0.7442411\ttotal: 923ms\tremaining: 2.71s\n",
      "254:\tlearn: 0.7440818\ttotal: 927ms\tremaining: 2.71s\n",
      "255:\tlearn: 0.7438966\ttotal: 931ms\tremaining: 2.7s\n",
      "256:\tlearn: 0.7437096\ttotal: 935ms\tremaining: 2.7s\n",
      "257:\tlearn: 0.7435359\ttotal: 938ms\tremaining: 2.7s\n",
      "258:\tlearn: 0.7433587\ttotal: 942ms\tremaining: 2.69s\n",
      "259:\tlearn: 0.7431879\ttotal: 946ms\tremaining: 2.69s\n",
      "260:\tlearn: 0.7430085\ttotal: 950ms\tremaining: 2.69s\n",
      "261:\tlearn: 0.7428255\ttotal: 953ms\tremaining: 2.69s\n",
      "262:\tlearn: 0.7427092\ttotal: 957ms\tremaining: 2.68s\n",
      "263:\tlearn: 0.7426316\ttotal: 961ms\tremaining: 2.68s\n",
      "264:\tlearn: 0.7424827\ttotal: 965ms\tremaining: 2.67s\n",
      "265:\tlearn: 0.7422431\ttotal: 968ms\tremaining: 2.67s\n",
      "266:\tlearn: 0.7420967\ttotal: 972ms\tremaining: 2.67s\n",
      "267:\tlearn: 0.7418849\ttotal: 975ms\tremaining: 2.66s\n",
      "268:\tlearn: 0.7417016\ttotal: 979ms\tremaining: 2.66s\n",
      "269:\tlearn: 0.7415546\ttotal: 982ms\tremaining: 2.66s\n",
      "270:\tlearn: 0.7413662\ttotal: 986ms\tremaining: 2.65s\n",
      "271:\tlearn: 0.7412192\ttotal: 990ms\tremaining: 2.65s\n",
      "272:\tlearn: 0.7410739\ttotal: 993ms\tremaining: 2.64s\n",
      "273:\tlearn: 0.7409218\ttotal: 997ms\tremaining: 2.64s\n",
      "274:\tlearn: 0.7407265\ttotal: 1s\tremaining: 2.64s\n",
      "275:\tlearn: 0.7405636\ttotal: 1s\tremaining: 2.63s\n",
      "276:\tlearn: 0.7403473\ttotal: 1.01s\tremaining: 2.63s\n",
      "277:\tlearn: 0.7401967\ttotal: 1.01s\tremaining: 2.63s\n",
      "278:\tlearn: 0.7400615\ttotal: 1.02s\tremaining: 2.63s\n",
      "279:\tlearn: 0.7399168\ttotal: 1.02s\tremaining: 2.62s\n",
      "280:\tlearn: 0.7397544\ttotal: 1.02s\tremaining: 2.62s\n",
      "281:\tlearn: 0.7396126\ttotal: 1.03s\tremaining: 2.62s\n",
      "282:\tlearn: 0.7394522\ttotal: 1.03s\tremaining: 2.61s\n",
      "283:\tlearn: 0.7392938\ttotal: 1.03s\tremaining: 2.61s\n",
      "284:\tlearn: 0.7391348\ttotal: 1.04s\tremaining: 2.6s\n",
      "285:\tlearn: 0.7390174\ttotal: 1.04s\tremaining: 2.6s\n",
      "286:\tlearn: 0.7388590\ttotal: 1.04s\tremaining: 2.6s\n",
      "287:\tlearn: 0.7387040\ttotal: 1.05s\tremaining: 2.59s\n",
      "288:\tlearn: 0.7385727\ttotal: 1.05s\tremaining: 2.59s\n",
      "289:\tlearn: 0.7383969\ttotal: 1.06s\tremaining: 2.59s\n",
      "290:\tlearn: 0.7381854\ttotal: 1.06s\tremaining: 2.58s\n",
      "291:\tlearn: 0.7380135\ttotal: 1.06s\tremaining: 2.58s\n",
      "292:\tlearn: 0.7378537\ttotal: 1.07s\tremaining: 2.57s\n",
      "293:\tlearn: 0.7376856\ttotal: 1.07s\tremaining: 2.57s\n",
      "294:\tlearn: 0.7374910\ttotal: 1.07s\tremaining: 2.57s\n",
      "295:\tlearn: 0.7373071\ttotal: 1.08s\tremaining: 2.56s\n",
      "296:\tlearn: 0.7371616\ttotal: 1.08s\tremaining: 2.56s\n",
      "297:\tlearn: 0.7369673\ttotal: 1.08s\tremaining: 2.56s\n",
      "298:\tlearn: 0.7368034\ttotal: 1.09s\tremaining: 2.55s\n",
      "299:\tlearn: 0.7366537\ttotal: 1.09s\tremaining: 2.55s\n",
      "300:\tlearn: 0.7364730\ttotal: 1.1s\tremaining: 2.55s\n",
      "301:\tlearn: 0.7362691\ttotal: 1.1s\tremaining: 2.54s\n",
      "302:\tlearn: 0.7361410\ttotal: 1.1s\tremaining: 2.54s\n",
      "303:\tlearn: 0.7360396\ttotal: 1.11s\tremaining: 2.54s\n",
      "304:\tlearn: 0.7359344\ttotal: 1.11s\tremaining: 2.53s\n",
      "305:\tlearn: 0.7358052\ttotal: 1.11s\tremaining: 2.53s\n",
      "306:\tlearn: 0.7356423\ttotal: 1.12s\tremaining: 2.52s\n",
      "307:\tlearn: 0.7355411\ttotal: 1.12s\tremaining: 2.52s\n",
      "308:\tlearn: 0.7353778\ttotal: 1.13s\tremaining: 2.52s\n",
      "309:\tlearn: 0.7352699\ttotal: 1.13s\tremaining: 2.51s\n",
      "310:\tlearn: 0.7350660\ttotal: 1.13s\tremaining: 2.51s\n",
      "311:\tlearn: 0.7349140\ttotal: 1.14s\tremaining: 2.5s\n",
      "312:\tlearn: 0.7347175\ttotal: 1.14s\tremaining: 2.5s\n",
      "313:\tlearn: 0.7345088\ttotal: 1.14s\tremaining: 2.5s\n",
      "314:\tlearn: 0.7343120\ttotal: 1.15s\tremaining: 2.49s\n",
      "315:\tlearn: 0.7341802\ttotal: 1.15s\tremaining: 2.49s\n",
      "316:\tlearn: 0.7340088\ttotal: 1.15s\tremaining: 2.49s\n",
      "317:\tlearn: 0.7339034\ttotal: 1.16s\tremaining: 2.48s\n",
      "318:\tlearn: 0.7337412\ttotal: 1.16s\tremaining: 2.48s\n",
      "319:\tlearn: 0.7335604\ttotal: 1.16s\tremaining: 2.48s\n",
      "320:\tlearn: 0.7334652\ttotal: 1.17s\tremaining: 2.47s\n",
      "321:\tlearn: 0.7333168\ttotal: 1.17s\tremaining: 2.47s\n",
      "322:\tlearn: 0.7331981\ttotal: 1.18s\tremaining: 2.46s\n",
      "323:\tlearn: 0.7330357\ttotal: 1.18s\tremaining: 2.46s\n",
      "324:\tlearn: 0.7329119\ttotal: 1.18s\tremaining: 2.46s\n",
      "325:\tlearn: 0.7327401\ttotal: 1.19s\tremaining: 2.45s\n",
      "326:\tlearn: 0.7325880\ttotal: 1.19s\tremaining: 2.45s\n",
      "327:\tlearn: 0.7323748\ttotal: 1.19s\tremaining: 2.45s\n",
      "328:\tlearn: 0.7322366\ttotal: 1.2s\tremaining: 2.44s\n",
      "329:\tlearn: 0.7321235\ttotal: 1.2s\tremaining: 2.44s\n",
      "330:\tlearn: 0.7319526\ttotal: 1.21s\tremaining: 2.44s\n",
      "331:\tlearn: 0.7318339\ttotal: 1.21s\tremaining: 2.43s\n",
      "332:\tlearn: 0.7316828\ttotal: 1.21s\tremaining: 2.43s\n",
      "333:\tlearn: 0.7315426\ttotal: 1.22s\tremaining: 2.43s\n",
      "334:\tlearn: 0.7313795\ttotal: 1.22s\tremaining: 2.42s\n",
      "335:\tlearn: 0.7312215\ttotal: 1.22s\tremaining: 2.42s\n",
      "336:\tlearn: 0.7311223\ttotal: 1.23s\tremaining: 2.42s\n",
      "337:\tlearn: 0.7309389\ttotal: 1.23s\tremaining: 2.41s\n",
      "338:\tlearn: 0.7307681\ttotal: 1.24s\tremaining: 2.41s\n",
      "339:\tlearn: 0.7306359\ttotal: 1.24s\tremaining: 2.41s\n",
      "340:\tlearn: 0.7304848\ttotal: 1.24s\tremaining: 2.4s\n",
      "341:\tlearn: 0.7303080\ttotal: 1.25s\tremaining: 2.4s\n",
      "342:\tlearn: 0.7301496\ttotal: 1.25s\tremaining: 2.4s\n",
      "343:\tlearn: 0.7299786\ttotal: 1.25s\tremaining: 2.39s\n",
      "344:\tlearn: 0.7298878\ttotal: 1.26s\tremaining: 2.39s\n",
      "345:\tlearn: 0.7297170\ttotal: 1.26s\tremaining: 2.38s\n",
      "346:\tlearn: 0.7295789\ttotal: 1.26s\tremaining: 2.38s\n",
      "347:\tlearn: 0.7294549\ttotal: 1.27s\tremaining: 2.38s\n",
      "348:\tlearn: 0.7293315\ttotal: 1.27s\tremaining: 2.37s\n",
      "349:\tlearn: 0.7291409\ttotal: 1.28s\tremaining: 2.37s\n",
      "350:\tlearn: 0.7289464\ttotal: 1.28s\tremaining: 2.37s\n",
      "351:\tlearn: 0.7287780\ttotal: 1.28s\tremaining: 2.36s\n",
      "352:\tlearn: 0.7286971\ttotal: 1.29s\tremaining: 2.36s\n",
      "353:\tlearn: 0.7285108\ttotal: 1.29s\tremaining: 2.35s\n",
      "354:\tlearn: 0.7283313\ttotal: 1.29s\tremaining: 2.35s\n",
      "355:\tlearn: 0.7281622\ttotal: 1.3s\tremaining: 2.35s\n",
      "356:\tlearn: 0.7280331\ttotal: 1.3s\tremaining: 2.34s\n",
      "357:\tlearn: 0.7279126\ttotal: 1.3s\tremaining: 2.34s\n",
      "358:\tlearn: 0.7277319\ttotal: 1.31s\tremaining: 2.34s\n",
      "359:\tlearn: 0.7275883\ttotal: 1.31s\tremaining: 2.33s\n",
      "360:\tlearn: 0.7274115\ttotal: 1.32s\tremaining: 2.33s\n",
      "361:\tlearn: 0.7272450\ttotal: 1.32s\tremaining: 2.33s\n",
      "362:\tlearn: 0.7271079\ttotal: 1.32s\tremaining: 2.32s\n",
      "363:\tlearn: 0.7269454\ttotal: 1.33s\tremaining: 2.32s\n",
      "364:\tlearn: 0.7267548\ttotal: 1.33s\tremaining: 2.31s\n",
      "365:\tlearn: 0.7266888\ttotal: 1.33s\tremaining: 2.31s\n",
      "366:\tlearn: 0.7264915\ttotal: 1.34s\tremaining: 2.31s\n",
      "367:\tlearn: 0.7263669\ttotal: 1.34s\tremaining: 2.31s\n",
      "368:\tlearn: 0.7261830\ttotal: 1.35s\tremaining: 2.3s\n",
      "369:\tlearn: 0.7260091\ttotal: 1.35s\tremaining: 2.3s\n",
      "370:\tlearn: 0.7259210\ttotal: 1.35s\tremaining: 2.29s\n",
      "371:\tlearn: 0.7258366\ttotal: 1.36s\tremaining: 2.29s\n",
      "372:\tlearn: 0.7256714\ttotal: 1.36s\tremaining: 2.29s\n",
      "373:\tlearn: 0.7255452\ttotal: 1.36s\tremaining: 2.28s\n",
      "374:\tlearn: 0.7254192\ttotal: 1.37s\tremaining: 2.28s\n",
      "375:\tlearn: 0.7252377\ttotal: 1.37s\tremaining: 2.28s\n",
      "376:\tlearn: 0.7250737\ttotal: 1.38s\tremaining: 2.27s\n",
      "377:\tlearn: 0.7249267\ttotal: 1.38s\tremaining: 2.27s\n",
      "378:\tlearn: 0.7248369\ttotal: 1.38s\tremaining: 2.27s\n",
      "379:\tlearn: 0.7246680\ttotal: 1.39s\tremaining: 2.26s\n",
      "380:\tlearn: 0.7245224\ttotal: 1.39s\tremaining: 2.26s\n",
      "381:\tlearn: 0.7243207\ttotal: 1.39s\tremaining: 2.25s\n",
      "382:\tlearn: 0.7241502\ttotal: 1.4s\tremaining: 2.25s\n",
      "383:\tlearn: 0.7239945\ttotal: 1.4s\tremaining: 2.25s\n",
      "384:\tlearn: 0.7238461\ttotal: 1.4s\tremaining: 2.24s\n",
      "385:\tlearn: 0.7237296\ttotal: 1.41s\tremaining: 2.24s\n",
      "386:\tlearn: 0.7236334\ttotal: 1.41s\tremaining: 2.23s\n",
      "387:\tlearn: 0.7234806\ttotal: 1.41s\tremaining: 2.23s\n",
      "388:\tlearn: 0.7233828\ttotal: 1.42s\tremaining: 2.23s\n",
      "389:\tlearn: 0.7232739\ttotal: 1.42s\tremaining: 2.22s\n",
      "390:\tlearn: 0.7231004\ttotal: 1.43s\tremaining: 2.22s\n",
      "391:\tlearn: 0.7229947\ttotal: 1.43s\tremaining: 2.22s\n",
      "392:\tlearn: 0.7228145\ttotal: 1.43s\tremaining: 2.21s\n",
      "393:\tlearn: 0.7227017\ttotal: 1.44s\tremaining: 2.21s\n",
      "394:\tlearn: 0.7225668\ttotal: 1.44s\tremaining: 2.21s\n",
      "395:\tlearn: 0.7224171\ttotal: 1.44s\tremaining: 2.2s\n",
      "396:\tlearn: 0.7223236\ttotal: 1.45s\tremaining: 2.2s\n",
      "397:\tlearn: 0.7221504\ttotal: 1.45s\tremaining: 2.19s\n",
      "398:\tlearn: 0.7220857\ttotal: 1.46s\tremaining: 2.19s\n",
      "399:\tlearn: 0.7219910\ttotal: 1.46s\tremaining: 2.19s\n",
      "400:\tlearn: 0.7218153\ttotal: 1.46s\tremaining: 2.18s\n",
      "401:\tlearn: 0.7216606\ttotal: 1.47s\tremaining: 2.18s\n",
      "402:\tlearn: 0.7215349\ttotal: 1.47s\tremaining: 2.18s\n",
      "403:\tlearn: 0.7213324\ttotal: 1.47s\tremaining: 2.17s\n",
      "404:\tlearn: 0.7211589\ttotal: 1.48s\tremaining: 2.17s\n",
      "405:\tlearn: 0.7210014\ttotal: 1.48s\tremaining: 2.17s\n",
      "406:\tlearn: 0.7208651\ttotal: 1.48s\tremaining: 2.16s\n",
      "407:\tlearn: 0.7207625\ttotal: 1.49s\tremaining: 2.16s\n",
      "408:\tlearn: 0.7206264\ttotal: 1.49s\tremaining: 2.15s\n",
      "409:\tlearn: 0.7205683\ttotal: 1.5s\tremaining: 2.15s\n",
      "410:\tlearn: 0.7204644\ttotal: 1.5s\tremaining: 2.15s\n",
      "411:\tlearn: 0.7203036\ttotal: 1.5s\tremaining: 2.14s\n",
      "412:\tlearn: 0.7201898\ttotal: 1.51s\tremaining: 2.14s\n",
      "413:\tlearn: 0.7200933\ttotal: 1.51s\tremaining: 2.14s\n",
      "414:\tlearn: 0.7199420\ttotal: 1.51s\tremaining: 2.13s\n",
      "415:\tlearn: 0.7197990\ttotal: 1.52s\tremaining: 2.13s\n",
      "416:\tlearn: 0.7196496\ttotal: 1.52s\tremaining: 2.13s\n",
      "417:\tlearn: 0.7194808\ttotal: 1.52s\tremaining: 2.12s\n",
      "418:\tlearn: 0.7193119\ttotal: 1.53s\tremaining: 2.12s\n",
      "419:\tlearn: 0.7191484\ttotal: 1.53s\tremaining: 2.12s\n",
      "420:\tlearn: 0.7190137\ttotal: 1.53s\tremaining: 2.11s\n",
      "421:\tlearn: 0.7188401\ttotal: 1.54s\tremaining: 2.11s\n",
      "422:\tlearn: 0.7187570\ttotal: 1.54s\tremaining: 2.1s\n",
      "423:\tlearn: 0.7186185\ttotal: 1.55s\tremaining: 2.1s\n",
      "424:\tlearn: 0.7184623\ttotal: 1.55s\tremaining: 2.1s\n",
      "425:\tlearn: 0.7182885\ttotal: 1.55s\tremaining: 2.09s\n",
      "426:\tlearn: 0.7182323\ttotal: 1.56s\tremaining: 2.09s\n",
      "427:\tlearn: 0.7181235\ttotal: 1.56s\tremaining: 2.09s\n",
      "428:\tlearn: 0.7180270\ttotal: 1.57s\tremaining: 2.08s\n",
      "429:\tlearn: 0.7179183\ttotal: 1.57s\tremaining: 2.08s\n",
      "430:\tlearn: 0.7177656\ttotal: 1.57s\tremaining: 2.08s\n",
      "431:\tlearn: 0.7176148\ttotal: 1.58s\tremaining: 2.07s\n",
      "432:\tlearn: 0.7175060\ttotal: 1.58s\tremaining: 2.07s\n",
      "433:\tlearn: 0.7173504\ttotal: 1.58s\tremaining: 2.07s\n",
      "434:\tlearn: 0.7172687\ttotal: 1.59s\tremaining: 2.06s\n",
      "435:\tlearn: 0.7171681\ttotal: 1.59s\tremaining: 2.06s\n",
      "436:\tlearn: 0.7170642\ttotal: 1.6s\tremaining: 2.06s\n",
      "437:\tlearn: 0.7169329\ttotal: 1.6s\tremaining: 2.05s\n",
      "438:\tlearn: 0.7168377\ttotal: 1.6s\tremaining: 2.05s\n",
      "439:\tlearn: 0.7167796\ttotal: 1.61s\tremaining: 2.04s\n",
      "440:\tlearn: 0.7166028\ttotal: 1.61s\tremaining: 2.04s\n",
      "441:\tlearn: 0.7164512\ttotal: 1.61s\tremaining: 2.04s\n",
      "442:\tlearn: 0.7163358\ttotal: 1.62s\tremaining: 2.04s\n",
      "443:\tlearn: 0.7162588\ttotal: 1.62s\tremaining: 2.03s\n",
      "444:\tlearn: 0.7161709\ttotal: 1.63s\tremaining: 2.03s\n",
      "445:\tlearn: 0.7160230\ttotal: 1.63s\tremaining: 2.02s\n",
      "446:\tlearn: 0.7159199\ttotal: 1.63s\tremaining: 2.02s\n",
      "447:\tlearn: 0.7158164\ttotal: 1.64s\tremaining: 2.02s\n",
      "448:\tlearn: 0.7157201\ttotal: 1.64s\tremaining: 2.02s\n",
      "449:\tlearn: 0.7155737\ttotal: 1.65s\tremaining: 2.01s\n",
      "450:\tlearn: 0.7154331\ttotal: 1.65s\tremaining: 2.01s\n",
      "451:\tlearn: 0.7152709\ttotal: 1.65s\tremaining: 2s\n",
      "452:\tlearn: 0.7151405\ttotal: 1.66s\tremaining: 2s\n",
      "453:\tlearn: 0.7149901\ttotal: 1.66s\tremaining: 2s\n",
      "454:\tlearn: 0.7149037\ttotal: 1.67s\tremaining: 2s\n",
      "455:\tlearn: 0.7147574\ttotal: 1.67s\tremaining: 1.99s\n",
      "456:\tlearn: 0.7146672\ttotal: 1.67s\tremaining: 1.99s\n",
      "457:\tlearn: 0.7145406\ttotal: 1.68s\tremaining: 1.99s\n",
      "458:\tlearn: 0.7144065\ttotal: 1.68s\tremaining: 1.98s\n",
      "459:\tlearn: 0.7142616\ttotal: 1.69s\tremaining: 1.98s\n",
      "460:\tlearn: 0.7141452\ttotal: 1.69s\tremaining: 1.97s\n",
      "461:\tlearn: 0.7140218\ttotal: 1.69s\tremaining: 1.97s\n",
      "462:\tlearn: 0.7139174\ttotal: 1.7s\tremaining: 1.97s\n",
      "463:\tlearn: 0.7137608\ttotal: 1.7s\tremaining: 1.96s\n",
      "464:\tlearn: 0.7136149\ttotal: 1.7s\tremaining: 1.96s\n",
      "465:\tlearn: 0.7134786\ttotal: 1.71s\tremaining: 1.96s\n",
      "466:\tlearn: 0.7133375\ttotal: 1.71s\tremaining: 1.95s\n",
      "467:\tlearn: 0.7131860\ttotal: 1.72s\tremaining: 1.95s\n",
      "468:\tlearn: 0.7130210\ttotal: 1.72s\tremaining: 1.95s\n",
      "469:\tlearn: 0.7128612\ttotal: 1.73s\tremaining: 1.95s\n",
      "470:\tlearn: 0.7127938\ttotal: 1.73s\tremaining: 1.94s\n",
      "471:\tlearn: 0.7127209\ttotal: 1.73s\tremaining: 1.94s\n",
      "472:\tlearn: 0.7126047\ttotal: 1.74s\tremaining: 1.94s\n",
      "473:\tlearn: 0.7125218\ttotal: 1.74s\tremaining: 1.93s\n",
      "474:\tlearn: 0.7123982\ttotal: 1.74s\tremaining: 1.93s\n",
      "475:\tlearn: 0.7123238\ttotal: 1.75s\tremaining: 1.92s\n",
      "476:\tlearn: 0.7122150\ttotal: 1.75s\tremaining: 1.92s\n",
      "477:\tlearn: 0.7120882\ttotal: 1.76s\tremaining: 1.92s\n",
      "478:\tlearn: 0.7119456\ttotal: 1.76s\tremaining: 1.91s\n",
      "479:\tlearn: 0.7117855\ttotal: 1.76s\tremaining: 1.91s\n",
      "480:\tlearn: 0.7116246\ttotal: 1.77s\tremaining: 1.91s\n",
      "481:\tlearn: 0.7114648\ttotal: 1.77s\tremaining: 1.9s\n",
      "482:\tlearn: 0.7113603\ttotal: 1.77s\tremaining: 1.9s\n",
      "483:\tlearn: 0.7112036\ttotal: 1.78s\tremaining: 1.9s\n",
      "484:\tlearn: 0.7110811\ttotal: 1.78s\tremaining: 1.89s\n",
      "485:\tlearn: 0.7109154\ttotal: 1.79s\tremaining: 1.89s\n",
      "486:\tlearn: 0.7108300\ttotal: 1.79s\tremaining: 1.89s\n",
      "487:\tlearn: 0.7106913\ttotal: 1.79s\tremaining: 1.88s\n",
      "488:\tlearn: 0.7105260\ttotal: 1.8s\tremaining: 1.88s\n",
      "489:\tlearn: 0.7104122\ttotal: 1.8s\tremaining: 1.88s\n",
      "490:\tlearn: 0.7102857\ttotal: 1.8s\tremaining: 1.87s\n",
      "491:\tlearn: 0.7102179\ttotal: 1.81s\tremaining: 1.87s\n",
      "492:\tlearn: 0.7100898\ttotal: 1.81s\tremaining: 1.86s\n",
      "493:\tlearn: 0.7099423\ttotal: 1.82s\tremaining: 1.86s\n",
      "494:\tlearn: 0.7097908\ttotal: 1.82s\tremaining: 1.86s\n",
      "495:\tlearn: 0.7096717\ttotal: 1.82s\tremaining: 1.85s\n",
      "496:\tlearn: 0.7096082\ttotal: 1.83s\tremaining: 1.85s\n",
      "497:\tlearn: 0.7094610\ttotal: 1.83s\tremaining: 1.84s\n",
      "498:\tlearn: 0.7093116\ttotal: 1.83s\tremaining: 1.84s\n",
      "499:\tlearn: 0.7092236\ttotal: 1.84s\tremaining: 1.84s\n",
      "500:\tlearn: 0.7090907\ttotal: 1.84s\tremaining: 1.83s\n",
      "501:\tlearn: 0.7089555\ttotal: 1.84s\tremaining: 1.83s\n",
      "502:\tlearn: 0.7088402\ttotal: 1.85s\tremaining: 1.83s\n",
      "503:\tlearn: 0.7087126\ttotal: 1.85s\tremaining: 1.82s\n",
      "504:\tlearn: 0.7085760\ttotal: 1.86s\tremaining: 1.82s\n",
      "505:\tlearn: 0.7084756\ttotal: 1.86s\tremaining: 1.82s\n",
      "506:\tlearn: 0.7084049\ttotal: 1.86s\tremaining: 1.81s\n",
      "507:\tlearn: 0.7082566\ttotal: 1.87s\tremaining: 1.81s\n",
      "508:\tlearn: 0.7081051\ttotal: 1.87s\tremaining: 1.81s\n",
      "509:\tlearn: 0.7079742\ttotal: 1.88s\tremaining: 1.8s\n",
      "510:\tlearn: 0.7078269\ttotal: 1.88s\tremaining: 1.8s\n",
      "511:\tlearn: 0.7076859\ttotal: 1.89s\tremaining: 1.8s\n",
      "512:\tlearn: 0.7075950\ttotal: 1.89s\tremaining: 1.79s\n",
      "513:\tlearn: 0.7074624\ttotal: 1.89s\tremaining: 1.79s\n",
      "514:\tlearn: 0.7073149\ttotal: 1.9s\tremaining: 1.79s\n",
      "515:\tlearn: 0.7072092\ttotal: 1.9s\tremaining: 1.78s\n",
      "516:\tlearn: 0.7070602\ttotal: 1.9s\tremaining: 1.78s\n",
      "517:\tlearn: 0.7069297\ttotal: 1.91s\tremaining: 1.77s\n",
      "518:\tlearn: 0.7068181\ttotal: 1.91s\tremaining: 1.77s\n",
      "519:\tlearn: 0.7066828\ttotal: 1.92s\tremaining: 1.77s\n",
      "520:\tlearn: 0.7065524\ttotal: 1.92s\tremaining: 1.76s\n",
      "521:\tlearn: 0.7064383\ttotal: 1.92s\tremaining: 1.76s\n",
      "522:\tlearn: 0.7063720\ttotal: 1.93s\tremaining: 1.76s\n",
      "523:\tlearn: 0.7062281\ttotal: 1.93s\tremaining: 1.75s\n",
      "524:\tlearn: 0.7060839\ttotal: 1.94s\tremaining: 1.75s\n",
      "525:\tlearn: 0.7059957\ttotal: 1.94s\tremaining: 1.75s\n",
      "526:\tlearn: 0.7059012\ttotal: 1.94s\tremaining: 1.74s\n",
      "527:\tlearn: 0.7057977\ttotal: 1.95s\tremaining: 1.74s\n",
      "528:\tlearn: 0.7057095\ttotal: 1.95s\tremaining: 1.74s\n",
      "529:\tlearn: 0.7055487\ttotal: 1.96s\tremaining: 1.73s\n",
      "530:\tlearn: 0.7054259\ttotal: 1.96s\tremaining: 1.73s\n",
      "531:\tlearn: 0.7053371\ttotal: 1.96s\tremaining: 1.73s\n",
      "532:\tlearn: 0.7051896\ttotal: 1.97s\tremaining: 1.72s\n",
      "533:\tlearn: 0.7050317\ttotal: 1.97s\tremaining: 1.72s\n",
      "534:\tlearn: 0.7049313\ttotal: 1.97s\tremaining: 1.72s\n",
      "535:\tlearn: 0.7048380\ttotal: 1.98s\tremaining: 1.71s\n",
      "536:\tlearn: 0.7047300\ttotal: 1.98s\tremaining: 1.71s\n",
      "537:\tlearn: 0.7045809\ttotal: 1.99s\tremaining: 1.71s\n",
      "538:\tlearn: 0.7044688\ttotal: 1.99s\tremaining: 1.7s\n",
      "539:\tlearn: 0.7043120\ttotal: 1.99s\tremaining: 1.7s\n",
      "540:\tlearn: 0.7042538\ttotal: 2s\tremaining: 1.7s\n",
      "541:\tlearn: 0.7041075\ttotal: 2s\tremaining: 1.69s\n",
      "542:\tlearn: 0.7040001\ttotal: 2s\tremaining: 1.69s\n",
      "543:\tlearn: 0.7038855\ttotal: 2.01s\tremaining: 1.68s\n",
      "544:\tlearn: 0.7038231\ttotal: 2.01s\tremaining: 1.68s\n",
      "545:\tlearn: 0.7036881\ttotal: 2.02s\tremaining: 1.68s\n",
      "546:\tlearn: 0.7035494\ttotal: 2.02s\tremaining: 1.67s\n",
      "547:\tlearn: 0.7034495\ttotal: 2.02s\tremaining: 1.67s\n",
      "548:\tlearn: 0.7032986\ttotal: 2.03s\tremaining: 1.67s\n",
      "549:\tlearn: 0.7032151\ttotal: 2.03s\tremaining: 1.66s\n",
      "550:\tlearn: 0.7031213\ttotal: 2.04s\tremaining: 1.66s\n",
      "551:\tlearn: 0.7030555\ttotal: 2.04s\tremaining: 1.66s\n",
      "552:\tlearn: 0.7029387\ttotal: 2.04s\tremaining: 1.65s\n",
      "553:\tlearn: 0.7028349\ttotal: 2.05s\tremaining: 1.65s\n",
      "554:\tlearn: 0.7027059\ttotal: 2.05s\tremaining: 1.64s\n",
      "555:\tlearn: 0.7025786\ttotal: 2.06s\tremaining: 1.64s\n",
      "556:\tlearn: 0.7024409\ttotal: 2.06s\tremaining: 1.64s\n",
      "557:\tlearn: 0.7023696\ttotal: 2.06s\tremaining: 1.63s\n",
      "558:\tlearn: 0.7022486\ttotal: 2.07s\tremaining: 1.63s\n",
      "559:\tlearn: 0.7020710\ttotal: 2.07s\tremaining: 1.63s\n",
      "560:\tlearn: 0.7019406\ttotal: 2.07s\tremaining: 1.62s\n",
      "561:\tlearn: 0.7017866\ttotal: 2.08s\tremaining: 1.62s\n",
      "562:\tlearn: 0.7016946\ttotal: 2.08s\tremaining: 1.61s\n",
      "563:\tlearn: 0.7015960\ttotal: 2.08s\tremaining: 1.61s\n",
      "564:\tlearn: 0.7015300\ttotal: 2.09s\tremaining: 1.61s\n",
      "565:\tlearn: 0.7014403\ttotal: 2.09s\tremaining: 1.6s\n",
      "566:\tlearn: 0.7013229\ttotal: 2.1s\tremaining: 1.6s\n",
      "567:\tlearn: 0.7012337\ttotal: 2.1s\tremaining: 1.6s\n",
      "568:\tlearn: 0.7011134\ttotal: 2.1s\tremaining: 1.59s\n",
      "569:\tlearn: 0.7009916\ttotal: 2.11s\tremaining: 1.59s\n",
      "570:\tlearn: 0.7008633\ttotal: 2.11s\tremaining: 1.59s\n",
      "571:\tlearn: 0.7007460\ttotal: 2.12s\tremaining: 1.58s\n",
      "572:\tlearn: 0.7006251\ttotal: 2.12s\tremaining: 1.58s\n",
      "573:\tlearn: 0.7005351\ttotal: 2.12s\tremaining: 1.57s\n",
      "574:\tlearn: 0.7004422\ttotal: 2.13s\tremaining: 1.57s\n",
      "575:\tlearn: 0.7003656\ttotal: 2.13s\tremaining: 1.57s\n",
      "576:\tlearn: 0.7001917\ttotal: 2.13s\tremaining: 1.56s\n",
      "577:\tlearn: 0.7000962\ttotal: 2.14s\tremaining: 1.56s\n",
      "578:\tlearn: 0.7000484\ttotal: 2.14s\tremaining: 1.56s\n",
      "579:\tlearn: 0.6999715\ttotal: 2.15s\tremaining: 1.55s\n",
      "580:\tlearn: 0.6998518\ttotal: 2.15s\tremaining: 1.55s\n",
      "581:\tlearn: 0.6997473\ttotal: 2.15s\tremaining: 1.55s\n",
      "582:\tlearn: 0.6996396\ttotal: 2.16s\tremaining: 1.54s\n",
      "583:\tlearn: 0.6995075\ttotal: 2.16s\tremaining: 1.54s\n",
      "584:\tlearn: 0.6994193\ttotal: 2.16s\tremaining: 1.53s\n",
      "585:\tlearn: 0.6993092\ttotal: 2.17s\tremaining: 1.53s\n",
      "586:\tlearn: 0.6991407\ttotal: 2.17s\tremaining: 1.53s\n",
      "587:\tlearn: 0.6990835\ttotal: 2.17s\tremaining: 1.52s\n",
      "588:\tlearn: 0.6989495\ttotal: 2.18s\tremaining: 1.52s\n",
      "589:\tlearn: 0.6988136\ttotal: 2.18s\tremaining: 1.52s\n",
      "590:\tlearn: 0.6987018\ttotal: 2.19s\tremaining: 1.51s\n",
      "591:\tlearn: 0.6985950\ttotal: 2.19s\tremaining: 1.51s\n",
      "592:\tlearn: 0.6984396\ttotal: 2.19s\tremaining: 1.51s\n",
      "593:\tlearn: 0.6983035\ttotal: 2.2s\tremaining: 1.5s\n",
      "594:\tlearn: 0.6981980\ttotal: 2.2s\tremaining: 1.5s\n",
      "595:\tlearn: 0.6980790\ttotal: 2.21s\tremaining: 1.5s\n",
      "596:\tlearn: 0.6979228\ttotal: 2.21s\tremaining: 1.49s\n",
      "597:\tlearn: 0.6978211\ttotal: 2.21s\tremaining: 1.49s\n",
      "598:\tlearn: 0.6977496\ttotal: 2.22s\tremaining: 1.49s\n",
      "599:\tlearn: 0.6976220\ttotal: 2.22s\tremaining: 1.48s\n",
      "600:\tlearn: 0.6974999\ttotal: 2.23s\tremaining: 1.48s\n",
      "601:\tlearn: 0.6973774\ttotal: 2.23s\tremaining: 1.47s\n",
      "602:\tlearn: 0.6972379\ttotal: 2.23s\tremaining: 1.47s\n",
      "603:\tlearn: 0.6971750\ttotal: 2.24s\tremaining: 1.47s\n",
      "604:\tlearn: 0.6970390\ttotal: 2.24s\tremaining: 1.46s\n",
      "605:\tlearn: 0.6969284\ttotal: 2.25s\tremaining: 1.46s\n",
      "606:\tlearn: 0.6968550\ttotal: 2.25s\tremaining: 1.46s\n",
      "607:\tlearn: 0.6967192\ttotal: 2.25s\tremaining: 1.45s\n",
      "608:\tlearn: 0.6966054\ttotal: 2.26s\tremaining: 1.45s\n",
      "609:\tlearn: 0.6965185\ttotal: 2.26s\tremaining: 1.45s\n",
      "610:\tlearn: 0.6964106\ttotal: 2.26s\tremaining: 1.44s\n",
      "611:\tlearn: 0.6962414\ttotal: 2.27s\tremaining: 1.44s\n",
      "612:\tlearn: 0.6961261\ttotal: 2.27s\tremaining: 1.43s\n",
      "613:\tlearn: 0.6960030\ttotal: 2.27s\tremaining: 1.43s\n",
      "614:\tlearn: 0.6959342\ttotal: 2.28s\tremaining: 1.43s\n",
      "615:\tlearn: 0.6957781\ttotal: 2.28s\tremaining: 1.42s\n",
      "616:\tlearn: 0.6957149\ttotal: 2.29s\tremaining: 1.42s\n",
      "617:\tlearn: 0.6955875\ttotal: 2.29s\tremaining: 1.42s\n",
      "618:\tlearn: 0.6954794\ttotal: 2.29s\tremaining: 1.41s\n",
      "619:\tlearn: 0.6953688\ttotal: 2.3s\tremaining: 1.41s\n",
      "620:\tlearn: 0.6952787\ttotal: 2.3s\tremaining: 1.4s\n",
      "621:\tlearn: 0.6952007\ttotal: 2.31s\tremaining: 1.4s\n",
      "622:\tlearn: 0.6950963\ttotal: 2.31s\tremaining: 1.4s\n",
      "623:\tlearn: 0.6949838\ttotal: 2.31s\tremaining: 1.39s\n",
      "624:\tlearn: 0.6949185\ttotal: 2.32s\tremaining: 1.39s\n",
      "625:\tlearn: 0.6947960\ttotal: 2.32s\tremaining: 1.39s\n",
      "626:\tlearn: 0.6946466\ttotal: 2.32s\tremaining: 1.38s\n",
      "627:\tlearn: 0.6945149\ttotal: 2.33s\tremaining: 1.38s\n",
      "628:\tlearn: 0.6943926\ttotal: 2.33s\tremaining: 1.38s\n",
      "629:\tlearn: 0.6942605\ttotal: 2.33s\tremaining: 1.37s\n",
      "630:\tlearn: 0.6941417\ttotal: 2.34s\tremaining: 1.37s\n",
      "631:\tlearn: 0.6940611\ttotal: 2.34s\tremaining: 1.36s\n",
      "632:\tlearn: 0.6939696\ttotal: 2.35s\tremaining: 1.36s\n",
      "633:\tlearn: 0.6938609\ttotal: 2.35s\tremaining: 1.36s\n",
      "634:\tlearn: 0.6937437\ttotal: 2.35s\tremaining: 1.35s\n",
      "635:\tlearn: 0.6935799\ttotal: 2.36s\tremaining: 1.35s\n",
      "636:\tlearn: 0.6934329\ttotal: 2.36s\tremaining: 1.34s\n",
      "637:\tlearn: 0.6932933\ttotal: 2.37s\tremaining: 1.34s\n",
      "638:\tlearn: 0.6931526\ttotal: 2.37s\tremaining: 1.34s\n",
      "639:\tlearn: 0.6930370\ttotal: 2.37s\tremaining: 1.33s\n",
      "640:\tlearn: 0.6929169\ttotal: 2.38s\tremaining: 1.33s\n",
      "641:\tlearn: 0.6927966\ttotal: 2.38s\tremaining: 1.33s\n",
      "642:\tlearn: 0.6927002\ttotal: 2.38s\tremaining: 1.32s\n",
      "643:\tlearn: 0.6925688\ttotal: 2.39s\tremaining: 1.32s\n",
      "644:\tlearn: 0.6924253\ttotal: 2.39s\tremaining: 1.32s\n",
      "645:\tlearn: 0.6923083\ttotal: 2.4s\tremaining: 1.31s\n",
      "646:\tlearn: 0.6922424\ttotal: 2.4s\tremaining: 1.31s\n",
      "647:\tlearn: 0.6921600\ttotal: 2.4s\tremaining: 1.3s\n",
      "648:\tlearn: 0.6920795\ttotal: 2.41s\tremaining: 1.3s\n",
      "649:\tlearn: 0.6919466\ttotal: 2.41s\tremaining: 1.3s\n",
      "650:\tlearn: 0.6917827\ttotal: 2.41s\tremaining: 1.29s\n",
      "651:\tlearn: 0.6917358\ttotal: 2.42s\tremaining: 1.29s\n",
      "652:\tlearn: 0.6916002\ttotal: 2.42s\tremaining: 1.29s\n",
      "653:\tlearn: 0.6915110\ttotal: 2.42s\tremaining: 1.28s\n",
      "654:\tlearn: 0.6913812\ttotal: 2.43s\tremaining: 1.28s\n",
      "655:\tlearn: 0.6912610\ttotal: 2.43s\tremaining: 1.28s\n",
      "656:\tlearn: 0.6911718\ttotal: 2.44s\tremaining: 1.27s\n",
      "657:\tlearn: 0.6910935\ttotal: 2.44s\tremaining: 1.27s\n",
      "658:\tlearn: 0.6909675\ttotal: 2.44s\tremaining: 1.26s\n",
      "659:\tlearn: 0.6908918\ttotal: 2.45s\tremaining: 1.26s\n",
      "660:\tlearn: 0.6907283\ttotal: 2.45s\tremaining: 1.26s\n",
      "661:\tlearn: 0.6906533\ttotal: 2.46s\tremaining: 1.25s\n",
      "662:\tlearn: 0.6905398\ttotal: 2.46s\tremaining: 1.25s\n",
      "663:\tlearn: 0.6904282\ttotal: 2.46s\tremaining: 1.25s\n",
      "664:\tlearn: 0.6902880\ttotal: 2.47s\tremaining: 1.24s\n",
      "665:\tlearn: 0.6901946\ttotal: 2.47s\tremaining: 1.24s\n",
      "666:\tlearn: 0.6900853\ttotal: 2.48s\tremaining: 1.24s\n",
      "667:\tlearn: 0.6899814\ttotal: 2.48s\tremaining: 1.23s\n",
      "668:\tlearn: 0.6898776\ttotal: 2.48s\tremaining: 1.23s\n",
      "669:\tlearn: 0.6898045\ttotal: 2.49s\tremaining: 1.23s\n",
      "670:\tlearn: 0.6896884\ttotal: 2.49s\tremaining: 1.22s\n",
      "671:\tlearn: 0.6895600\ttotal: 2.5s\tremaining: 1.22s\n",
      "672:\tlearn: 0.6894716\ttotal: 2.5s\tremaining: 1.21s\n",
      "673:\tlearn: 0.6894245\ttotal: 2.5s\tremaining: 1.21s\n",
      "674:\tlearn: 0.6893139\ttotal: 2.51s\tremaining: 1.21s\n",
      "675:\tlearn: 0.6892086\ttotal: 2.51s\tremaining: 1.2s\n",
      "676:\tlearn: 0.6891181\ttotal: 2.51s\tremaining: 1.2s\n",
      "677:\tlearn: 0.6889698\ttotal: 2.52s\tremaining: 1.2s\n",
      "678:\tlearn: 0.6888448\ttotal: 2.52s\tremaining: 1.19s\n",
      "679:\tlearn: 0.6887963\ttotal: 2.52s\tremaining: 1.19s\n",
      "680:\tlearn: 0.6887177\ttotal: 2.53s\tremaining: 1.18s\n",
      "681:\tlearn: 0.6885814\ttotal: 2.53s\tremaining: 1.18s\n",
      "682:\tlearn: 0.6884743\ttotal: 2.54s\tremaining: 1.18s\n",
      "683:\tlearn: 0.6883215\ttotal: 2.54s\tremaining: 1.17s\n",
      "684:\tlearn: 0.6882000\ttotal: 2.54s\tremaining: 1.17s\n",
      "685:\tlearn: 0.6880771\ttotal: 2.55s\tremaining: 1.17s\n",
      "686:\tlearn: 0.6879795\ttotal: 2.55s\tremaining: 1.16s\n",
      "687:\tlearn: 0.6878776\ttotal: 2.55s\tremaining: 1.16s\n",
      "688:\tlearn: 0.6877661\ttotal: 2.56s\tremaining: 1.15s\n",
      "689:\tlearn: 0.6876720\ttotal: 2.56s\tremaining: 1.15s\n",
      "690:\tlearn: 0.6875690\ttotal: 2.56s\tremaining: 1.15s\n",
      "691:\tlearn: 0.6875309\ttotal: 2.57s\tremaining: 1.14s\n",
      "692:\tlearn: 0.6874488\ttotal: 2.57s\tremaining: 1.14s\n",
      "693:\tlearn: 0.6873325\ttotal: 2.58s\tremaining: 1.14s\n",
      "694:\tlearn: 0.6872695\ttotal: 2.58s\tremaining: 1.13s\n",
      "695:\tlearn: 0.6871594\ttotal: 2.58s\tremaining: 1.13s\n",
      "696:\tlearn: 0.6870569\ttotal: 2.59s\tremaining: 1.12s\n",
      "697:\tlearn: 0.6869614\ttotal: 2.59s\tremaining: 1.12s\n",
      "698:\tlearn: 0.6867912\ttotal: 2.59s\tremaining: 1.12s\n",
      "699:\tlearn: 0.6867250\ttotal: 2.6s\tremaining: 1.11s\n",
      "700:\tlearn: 0.6865797\ttotal: 2.6s\tremaining: 1.11s\n",
      "701:\tlearn: 0.6864713\ttotal: 2.61s\tremaining: 1.11s\n",
      "702:\tlearn: 0.6863401\ttotal: 2.61s\tremaining: 1.1s\n",
      "703:\tlearn: 0.6862405\ttotal: 2.61s\tremaining: 1.1s\n",
      "704:\tlearn: 0.6861182\ttotal: 2.62s\tremaining: 1.09s\n",
      "705:\tlearn: 0.6860392\ttotal: 2.62s\tremaining: 1.09s\n",
      "706:\tlearn: 0.6858881\ttotal: 2.63s\tremaining: 1.09s\n",
      "707:\tlearn: 0.6858184\ttotal: 2.63s\tremaining: 1.08s\n",
      "708:\tlearn: 0.6857133\ttotal: 2.63s\tremaining: 1.08s\n",
      "709:\tlearn: 0.6856401\ttotal: 2.64s\tremaining: 1.08s\n",
      "710:\tlearn: 0.6855394\ttotal: 2.64s\tremaining: 1.07s\n",
      "711:\tlearn: 0.6854866\ttotal: 2.64s\tremaining: 1.07s\n",
      "712:\tlearn: 0.6854217\ttotal: 2.65s\tremaining: 1.06s\n",
      "713:\tlearn: 0.6853261\ttotal: 2.65s\tremaining: 1.06s\n",
      "714:\tlearn: 0.6852025\ttotal: 2.65s\tremaining: 1.06s\n",
      "715:\tlearn: 0.6851344\ttotal: 2.66s\tremaining: 1.05s\n",
      "716:\tlearn: 0.6850722\ttotal: 2.66s\tremaining: 1.05s\n",
      "717:\tlearn: 0.6849885\ttotal: 2.67s\tremaining: 1.05s\n",
      "718:\tlearn: 0.6848782\ttotal: 2.67s\tremaining: 1.04s\n",
      "719:\tlearn: 0.6847707\ttotal: 2.67s\tremaining: 1.04s\n",
      "720:\tlearn: 0.6847012\ttotal: 2.68s\tremaining: 1.03s\n",
      "721:\tlearn: 0.6845946\ttotal: 2.68s\tremaining: 1.03s\n",
      "722:\tlearn: 0.6844515\ttotal: 2.68s\tremaining: 1.03s\n",
      "723:\tlearn: 0.6843638\ttotal: 2.69s\tremaining: 1.02s\n",
      "724:\tlearn: 0.6842513\ttotal: 2.69s\tremaining: 1.02s\n",
      "725:\tlearn: 0.6841608\ttotal: 2.69s\tremaining: 1.02s\n",
      "726:\tlearn: 0.6840815\ttotal: 2.7s\tremaining: 1.01s\n",
      "727:\tlearn: 0.6839460\ttotal: 2.7s\tremaining: 1.01s\n",
      "728:\tlearn: 0.6838653\ttotal: 2.71s\tremaining: 1.01s\n",
      "729:\tlearn: 0.6837717\ttotal: 2.71s\tremaining: 1s\n",
      "730:\tlearn: 0.6836680\ttotal: 2.71s\tremaining: 999ms\n",
      "731:\tlearn: 0.6835345\ttotal: 2.72s\tremaining: 995ms\n",
      "732:\tlearn: 0.6834636\ttotal: 2.72s\tremaining: 992ms\n",
      "733:\tlearn: 0.6833401\ttotal: 2.73s\tremaining: 988ms\n",
      "734:\tlearn: 0.6832252\ttotal: 2.73s\tremaining: 984ms\n",
      "735:\tlearn: 0.6831360\ttotal: 2.73s\tremaining: 980ms\n",
      "736:\tlearn: 0.6830376\ttotal: 2.74s\tremaining: 977ms\n",
      "737:\tlearn: 0.6829024\ttotal: 2.74s\tremaining: 973ms\n",
      "738:\tlearn: 0.6828069\ttotal: 2.74s\tremaining: 969ms\n",
      "739:\tlearn: 0.6826845\ttotal: 2.75s\tremaining: 966ms\n",
      "740:\tlearn: 0.6825536\ttotal: 2.75s\tremaining: 962ms\n",
      "741:\tlearn: 0.6824662\ttotal: 2.75s\tremaining: 958ms\n",
      "742:\tlearn: 0.6823984\ttotal: 2.76s\tremaining: 954ms\n",
      "743:\tlearn: 0.6822900\ttotal: 2.76s\tremaining: 951ms\n",
      "744:\tlearn: 0.6821847\ttotal: 2.77s\tremaining: 947ms\n",
      "745:\tlearn: 0.6821191\ttotal: 2.77s\tremaining: 943ms\n",
      "746:\tlearn: 0.6820551\ttotal: 2.77s\tremaining: 940ms\n",
      "747:\tlearn: 0.6819521\ttotal: 2.78s\tremaining: 936ms\n",
      "748:\tlearn: 0.6818624\ttotal: 2.78s\tremaining: 932ms\n",
      "749:\tlearn: 0.6817384\ttotal: 2.78s\tremaining: 928ms\n",
      "750:\tlearn: 0.6816760\ttotal: 2.79s\tremaining: 925ms\n",
      "751:\tlearn: 0.6815754\ttotal: 2.79s\tremaining: 921ms\n",
      "752:\tlearn: 0.6815009\ttotal: 2.79s\tremaining: 917ms\n",
      "753:\tlearn: 0.6813758\ttotal: 2.8s\tremaining: 913ms\n",
      "754:\tlearn: 0.6812956\ttotal: 2.8s\tremaining: 910ms\n",
      "755:\tlearn: 0.6811788\ttotal: 2.81s\tremaining: 906ms\n",
      "756:\tlearn: 0.6811242\ttotal: 2.81s\tremaining: 902ms\n",
      "757:\tlearn: 0.6810726\ttotal: 2.81s\tremaining: 898ms\n",
      "758:\tlearn: 0.6809972\ttotal: 2.82s\tremaining: 895ms\n",
      "759:\tlearn: 0.6808844\ttotal: 2.82s\tremaining: 891ms\n",
      "760:\tlearn: 0.6807784\ttotal: 2.82s\tremaining: 887ms\n",
      "761:\tlearn: 0.6807106\ttotal: 2.83s\tremaining: 884ms\n",
      "762:\tlearn: 0.6806505\ttotal: 2.83s\tremaining: 880ms\n",
      "763:\tlearn: 0.6805635\ttotal: 2.84s\tremaining: 876ms\n",
      "764:\tlearn: 0.6804918\ttotal: 2.84s\tremaining: 872ms\n",
      "765:\tlearn: 0.6803847\ttotal: 2.84s\tremaining: 869ms\n",
      "766:\tlearn: 0.6803038\ttotal: 2.85s\tremaining: 865ms\n",
      "767:\tlearn: 0.6802712\ttotal: 2.85s\tremaining: 861ms\n",
      "768:\tlearn: 0.6802398\ttotal: 2.85s\tremaining: 857ms\n",
      "769:\tlearn: 0.6801637\ttotal: 2.86s\tremaining: 854ms\n",
      "770:\tlearn: 0.6800785\ttotal: 2.86s\tremaining: 850ms\n",
      "771:\tlearn: 0.6800064\ttotal: 2.87s\tremaining: 846ms\n",
      "772:\tlearn: 0.6799494\ttotal: 2.87s\tremaining: 843ms\n",
      "773:\tlearn: 0.6798669\ttotal: 2.87s\tremaining: 839ms\n",
      "774:\tlearn: 0.6797408\ttotal: 2.88s\tremaining: 835ms\n",
      "775:\tlearn: 0.6797031\ttotal: 2.88s\tremaining: 832ms\n",
      "776:\tlearn: 0.6796343\ttotal: 2.88s\tremaining: 828ms\n",
      "777:\tlearn: 0.6795567\ttotal: 2.89s\tremaining: 824ms\n",
      "778:\tlearn: 0.6794604\ttotal: 2.89s\tremaining: 820ms\n",
      "779:\tlearn: 0.6793605\ttotal: 2.9s\tremaining: 817ms\n",
      "780:\tlearn: 0.6792970\ttotal: 2.9s\tremaining: 813ms\n",
      "781:\tlearn: 0.6791847\ttotal: 2.9s\tremaining: 809ms\n",
      "782:\tlearn: 0.6790542\ttotal: 2.91s\tremaining: 806ms\n",
      "783:\tlearn: 0.6789257\ttotal: 2.91s\tremaining: 802ms\n",
      "784:\tlearn: 0.6788740\ttotal: 2.91s\tremaining: 798ms\n",
      "785:\tlearn: 0.6787235\ttotal: 2.92s\tremaining: 794ms\n",
      "786:\tlearn: 0.6786240\ttotal: 2.92s\tremaining: 791ms\n",
      "787:\tlearn: 0.6785625\ttotal: 2.92s\tremaining: 787ms\n",
      "788:\tlearn: 0.6784767\ttotal: 2.93s\tremaining: 783ms\n",
      "789:\tlearn: 0.6783394\ttotal: 2.93s\tremaining: 780ms\n",
      "790:\tlearn: 0.6782793\ttotal: 2.94s\tremaining: 776ms\n",
      "791:\tlearn: 0.6781577\ttotal: 2.94s\tremaining: 772ms\n",
      "792:\tlearn: 0.6780677\ttotal: 2.94s\tremaining: 768ms\n",
      "793:\tlearn: 0.6779529\ttotal: 2.95s\tremaining: 765ms\n",
      "794:\tlearn: 0.6778540\ttotal: 2.95s\tremaining: 761ms\n",
      "795:\tlearn: 0.6777011\ttotal: 2.95s\tremaining: 757ms\n",
      "796:\tlearn: 0.6775791\ttotal: 2.96s\tremaining: 754ms\n",
      "797:\tlearn: 0.6774519\ttotal: 2.96s\tremaining: 750ms\n",
      "798:\tlearn: 0.6773583\ttotal: 2.96s\tremaining: 746ms\n",
      "799:\tlearn: 0.6772228\ttotal: 2.97s\tremaining: 742ms\n",
      "800:\tlearn: 0.6771436\ttotal: 2.97s\tremaining: 739ms\n",
      "801:\tlearn: 0.6770660\ttotal: 2.98s\tremaining: 735ms\n",
      "802:\tlearn: 0.6769686\ttotal: 2.98s\tremaining: 731ms\n",
      "803:\tlearn: 0.6769141\ttotal: 2.98s\tremaining: 727ms\n",
      "804:\tlearn: 0.6768595\ttotal: 2.99s\tremaining: 724ms\n",
      "805:\tlearn: 0.6767238\ttotal: 2.99s\tremaining: 720ms\n",
      "806:\tlearn: 0.6766046\ttotal: 2.99s\tremaining: 716ms\n",
      "807:\tlearn: 0.6765200\ttotal: 3s\tremaining: 712ms\n",
      "808:\tlearn: 0.6764204\ttotal: 3s\tremaining: 709ms\n",
      "809:\tlearn: 0.6762847\ttotal: 3s\tremaining: 705ms\n",
      "810:\tlearn: 0.6761583\ttotal: 3.01s\tremaining: 701ms\n",
      "811:\tlearn: 0.6760510\ttotal: 3.01s\tremaining: 698ms\n",
      "812:\tlearn: 0.6759706\ttotal: 3.02s\tremaining: 694ms\n",
      "813:\tlearn: 0.6759040\ttotal: 3.02s\tremaining: 690ms\n",
      "814:\tlearn: 0.6758439\ttotal: 3.02s\tremaining: 687ms\n",
      "815:\tlearn: 0.6757317\ttotal: 3.03s\tremaining: 683ms\n",
      "816:\tlearn: 0.6756809\ttotal: 3.03s\tremaining: 679ms\n",
      "817:\tlearn: 0.6755576\ttotal: 3.04s\tremaining: 676ms\n",
      "818:\tlearn: 0.6754509\ttotal: 3.04s\tremaining: 672ms\n",
      "819:\tlearn: 0.6753164\ttotal: 3.04s\tremaining: 668ms\n",
      "820:\tlearn: 0.6752011\ttotal: 3.05s\tremaining: 665ms\n",
      "821:\tlearn: 0.6751048\ttotal: 3.05s\tremaining: 661ms\n",
      "822:\tlearn: 0.6749786\ttotal: 3.06s\tremaining: 657ms\n",
      "823:\tlearn: 0.6749155\ttotal: 3.06s\tremaining: 653ms\n",
      "824:\tlearn: 0.6748749\ttotal: 3.06s\tremaining: 650ms\n",
      "825:\tlearn: 0.6747349\ttotal: 3.07s\tremaining: 646ms\n",
      "826:\tlearn: 0.6746174\ttotal: 3.07s\tremaining: 642ms\n",
      "827:\tlearn: 0.6745266\ttotal: 3.07s\tremaining: 639ms\n",
      "828:\tlearn: 0.6744275\ttotal: 3.08s\tremaining: 635ms\n",
      "829:\tlearn: 0.6743521\ttotal: 3.08s\tremaining: 631ms\n",
      "830:\tlearn: 0.6742639\ttotal: 3.08s\tremaining: 627ms\n",
      "831:\tlearn: 0.6741950\ttotal: 3.09s\tremaining: 624ms\n",
      "832:\tlearn: 0.6740570\ttotal: 3.09s\tremaining: 620ms\n",
      "833:\tlearn: 0.6739984\ttotal: 3.1s\tremaining: 616ms\n",
      "834:\tlearn: 0.6739032\ttotal: 3.1s\tremaining: 613ms\n",
      "835:\tlearn: 0.6737538\ttotal: 3.1s\tremaining: 609ms\n",
      "836:\tlearn: 0.6736462\ttotal: 3.11s\tremaining: 605ms\n",
      "837:\tlearn: 0.6735220\ttotal: 3.11s\tremaining: 602ms\n",
      "838:\tlearn: 0.6734178\ttotal: 3.12s\tremaining: 598ms\n",
      "839:\tlearn: 0.6732671\ttotal: 3.12s\tremaining: 594ms\n",
      "840:\tlearn: 0.6731487\ttotal: 3.12s\tremaining: 590ms\n",
      "841:\tlearn: 0.6730994\ttotal: 3.13s\tremaining: 587ms\n",
      "842:\tlearn: 0.6730265\ttotal: 3.13s\tremaining: 583ms\n",
      "843:\tlearn: 0.6729836\ttotal: 3.13s\tremaining: 579ms\n",
      "844:\tlearn: 0.6728843\ttotal: 3.14s\tremaining: 575ms\n",
      "845:\tlearn: 0.6728189\ttotal: 3.14s\tremaining: 572ms\n",
      "846:\tlearn: 0.6727352\ttotal: 3.14s\tremaining: 568ms\n",
      "847:\tlearn: 0.6726125\ttotal: 3.15s\tremaining: 564ms\n",
      "848:\tlearn: 0.6724993\ttotal: 3.15s\tremaining: 561ms\n",
      "849:\tlearn: 0.6724003\ttotal: 3.15s\tremaining: 557ms\n",
      "850:\tlearn: 0.6722827\ttotal: 3.16s\tremaining: 553ms\n",
      "851:\tlearn: 0.6722183\ttotal: 3.16s\tremaining: 549ms\n",
      "852:\tlearn: 0.6721373\ttotal: 3.17s\tremaining: 546ms\n",
      "853:\tlearn: 0.6720250\ttotal: 3.17s\tremaining: 542ms\n",
      "854:\tlearn: 0.6719142\ttotal: 3.17s\tremaining: 538ms\n",
      "855:\tlearn: 0.6718139\ttotal: 3.18s\tremaining: 535ms\n",
      "856:\tlearn: 0.6717141\ttotal: 3.18s\tremaining: 531ms\n",
      "857:\tlearn: 0.6716325\ttotal: 3.19s\tremaining: 527ms\n",
      "858:\tlearn: 0.6715455\ttotal: 3.19s\tremaining: 523ms\n",
      "859:\tlearn: 0.6714947\ttotal: 3.19s\tremaining: 520ms\n",
      "860:\tlearn: 0.6714501\ttotal: 3.2s\tremaining: 516ms\n",
      "861:\tlearn: 0.6713588\ttotal: 3.2s\tremaining: 512ms\n",
      "862:\tlearn: 0.6712611\ttotal: 3.2s\tremaining: 509ms\n",
      "863:\tlearn: 0.6711955\ttotal: 3.21s\tremaining: 505ms\n",
      "864:\tlearn: 0.6711386\ttotal: 3.21s\tremaining: 501ms\n",
      "865:\tlearn: 0.6710690\ttotal: 3.21s\tremaining: 498ms\n",
      "866:\tlearn: 0.6709630\ttotal: 3.22s\tremaining: 494ms\n",
      "867:\tlearn: 0.6708447\ttotal: 3.22s\tremaining: 490ms\n",
      "868:\tlearn: 0.6707657\ttotal: 3.23s\tremaining: 487ms\n",
      "869:\tlearn: 0.6706295\ttotal: 3.23s\tremaining: 483ms\n",
      "870:\tlearn: 0.6705725\ttotal: 3.23s\tremaining: 479ms\n",
      "871:\tlearn: 0.6704517\ttotal: 3.24s\tremaining: 476ms\n",
      "872:\tlearn: 0.6703636\ttotal: 3.24s\tremaining: 472ms\n",
      "873:\tlearn: 0.6702559\ttotal: 3.25s\tremaining: 468ms\n",
      "874:\tlearn: 0.6701539\ttotal: 3.25s\tremaining: 464ms\n",
      "875:\tlearn: 0.6700665\ttotal: 3.25s\tremaining: 461ms\n",
      "876:\tlearn: 0.6699406\ttotal: 3.26s\tremaining: 457ms\n",
      "877:\tlearn: 0.6698810\ttotal: 3.26s\tremaining: 453ms\n",
      "878:\tlearn: 0.6697493\ttotal: 3.27s\tremaining: 450ms\n",
      "879:\tlearn: 0.6696795\ttotal: 3.27s\tremaining: 446ms\n",
      "880:\tlearn: 0.6695656\ttotal: 3.27s\tremaining: 442ms\n",
      "881:\tlearn: 0.6694668\ttotal: 3.28s\tremaining: 438ms\n",
      "882:\tlearn: 0.6693205\ttotal: 3.28s\tremaining: 435ms\n",
      "883:\tlearn: 0.6691843\ttotal: 3.29s\tremaining: 431ms\n",
      "884:\tlearn: 0.6691137\ttotal: 3.29s\tremaining: 427ms\n",
      "885:\tlearn: 0.6689914\ttotal: 3.29s\tremaining: 424ms\n",
      "886:\tlearn: 0.6689185\ttotal: 3.3s\tremaining: 420ms\n",
      "887:\tlearn: 0.6688196\ttotal: 3.3s\tremaining: 416ms\n",
      "888:\tlearn: 0.6687274\ttotal: 3.3s\tremaining: 413ms\n",
      "889:\tlearn: 0.6686303\ttotal: 3.31s\tremaining: 409ms\n",
      "890:\tlearn: 0.6685785\ttotal: 3.31s\tremaining: 405ms\n",
      "891:\tlearn: 0.6685179\ttotal: 3.32s\tremaining: 402ms\n",
      "892:\tlearn: 0.6684098\ttotal: 3.32s\tremaining: 398ms\n",
      "893:\tlearn: 0.6682958\ttotal: 3.32s\tremaining: 394ms\n",
      "894:\tlearn: 0.6682658\ttotal: 3.33s\tremaining: 390ms\n",
      "895:\tlearn: 0.6681964\ttotal: 3.33s\tremaining: 387ms\n",
      "896:\tlearn: 0.6680826\ttotal: 3.33s\tremaining: 383ms\n",
      "897:\tlearn: 0.6679924\ttotal: 3.34s\tremaining: 379ms\n",
      "898:\tlearn: 0.6678647\ttotal: 3.34s\tremaining: 376ms\n",
      "899:\tlearn: 0.6677786\ttotal: 3.35s\tremaining: 372ms\n",
      "900:\tlearn: 0.6676549\ttotal: 3.35s\tremaining: 368ms\n",
      "901:\tlearn: 0.6675193\ttotal: 3.35s\tremaining: 365ms\n",
      "902:\tlearn: 0.6673957\ttotal: 3.36s\tremaining: 361ms\n",
      "903:\tlearn: 0.6673217\ttotal: 3.36s\tremaining: 357ms\n",
      "904:\tlearn: 0.6672152\ttotal: 3.37s\tremaining: 353ms\n",
      "905:\tlearn: 0.6671659\ttotal: 3.37s\tremaining: 350ms\n",
      "906:\tlearn: 0.6671127\ttotal: 3.37s\tremaining: 346ms\n",
      "907:\tlearn: 0.6670530\ttotal: 3.38s\tremaining: 342ms\n",
      "908:\tlearn: 0.6669327\ttotal: 3.38s\tremaining: 338ms\n",
      "909:\tlearn: 0.6668434\ttotal: 3.38s\tremaining: 335ms\n",
      "910:\tlearn: 0.6667267\ttotal: 3.39s\tremaining: 331ms\n",
      "911:\tlearn: 0.6666146\ttotal: 3.39s\tremaining: 327ms\n",
      "912:\tlearn: 0.6665501\ttotal: 3.4s\tremaining: 324ms\n",
      "913:\tlearn: 0.6664430\ttotal: 3.4s\tremaining: 320ms\n",
      "914:\tlearn: 0.6663287\ttotal: 3.4s\tremaining: 316ms\n",
      "915:\tlearn: 0.6662103\ttotal: 3.41s\tremaining: 313ms\n",
      "916:\tlearn: 0.6661214\ttotal: 3.41s\tremaining: 309ms\n",
      "917:\tlearn: 0.6660303\ttotal: 3.44s\tremaining: 307ms\n",
      "918:\tlearn: 0.6659383\ttotal: 3.44s\tremaining: 304ms\n",
      "919:\tlearn: 0.6658549\ttotal: 3.45s\tremaining: 300ms\n",
      "920:\tlearn: 0.6658260\ttotal: 3.46s\tremaining: 296ms\n",
      "921:\tlearn: 0.6657655\ttotal: 3.46s\tremaining: 293ms\n",
      "922:\tlearn: 0.6656324\ttotal: 3.46s\tremaining: 289ms\n",
      "923:\tlearn: 0.6655311\ttotal: 3.47s\tremaining: 285ms\n",
      "924:\tlearn: 0.6654280\ttotal: 3.47s\tremaining: 282ms\n",
      "925:\tlearn: 0.6652828\ttotal: 3.48s\tremaining: 278ms\n",
      "926:\tlearn: 0.6652107\ttotal: 3.48s\tremaining: 274ms\n",
      "927:\tlearn: 0.6651756\ttotal: 3.48s\tremaining: 270ms\n",
      "928:\tlearn: 0.6650781\ttotal: 3.49s\tremaining: 267ms\n",
      "929:\tlearn: 0.6649526\ttotal: 3.49s\tremaining: 263ms\n",
      "930:\tlearn: 0.6648692\ttotal: 3.49s\tremaining: 259ms\n",
      "931:\tlearn: 0.6648246\ttotal: 3.5s\tremaining: 255ms\n",
      "932:\tlearn: 0.6647520\ttotal: 3.5s\tremaining: 251ms\n",
      "933:\tlearn: 0.6646604\ttotal: 3.5s\tremaining: 248ms\n",
      "934:\tlearn: 0.6645535\ttotal: 3.51s\tremaining: 244ms\n",
      "935:\tlearn: 0.6644377\ttotal: 3.51s\tremaining: 240ms\n",
      "936:\tlearn: 0.6643204\ttotal: 3.52s\tremaining: 236ms\n",
      "937:\tlearn: 0.6642287\ttotal: 3.52s\tremaining: 233ms\n",
      "938:\tlearn: 0.6641005\ttotal: 3.52s\tremaining: 229ms\n",
      "939:\tlearn: 0.6639929\ttotal: 3.53s\tremaining: 225ms\n",
      "940:\tlearn: 0.6638933\ttotal: 3.53s\tremaining: 221ms\n",
      "941:\tlearn: 0.6638052\ttotal: 3.53s\tremaining: 218ms\n",
      "942:\tlearn: 0.6637548\ttotal: 3.54s\tremaining: 214ms\n",
      "943:\tlearn: 0.6636707\ttotal: 3.54s\tremaining: 210ms\n",
      "944:\tlearn: 0.6635957\ttotal: 3.55s\tremaining: 206ms\n",
      "945:\tlearn: 0.6635210\ttotal: 3.55s\tremaining: 203ms\n",
      "946:\tlearn: 0.6634338\ttotal: 3.55s\tremaining: 199ms\n",
      "947:\tlearn: 0.6633309\ttotal: 3.56s\tremaining: 195ms\n",
      "948:\tlearn: 0.6632465\ttotal: 3.56s\tremaining: 191ms\n",
      "949:\tlearn: 0.6631655\ttotal: 3.56s\tremaining: 188ms\n",
      "950:\tlearn: 0.6630627\ttotal: 3.57s\tremaining: 184ms\n",
      "951:\tlearn: 0.6629651\ttotal: 3.57s\tremaining: 180ms\n",
      "952:\tlearn: 0.6628770\ttotal: 3.58s\tremaining: 176ms\n",
      "953:\tlearn: 0.6627987\ttotal: 3.58s\tremaining: 173ms\n",
      "954:\tlearn: 0.6627297\ttotal: 3.58s\tremaining: 169ms\n",
      "955:\tlearn: 0.6626021\ttotal: 3.59s\tremaining: 165ms\n",
      "956:\tlearn: 0.6624987\ttotal: 3.59s\tremaining: 161ms\n",
      "957:\tlearn: 0.6623863\ttotal: 3.6s\tremaining: 158ms\n",
      "958:\tlearn: 0.6622895\ttotal: 3.6s\tremaining: 154ms\n",
      "959:\tlearn: 0.6622285\ttotal: 3.6s\tremaining: 150ms\n",
      "960:\tlearn: 0.6621301\ttotal: 3.61s\tremaining: 146ms\n",
      "961:\tlearn: 0.6620394\ttotal: 3.61s\tremaining: 143ms\n",
      "962:\tlearn: 0.6619652\ttotal: 3.62s\tremaining: 139ms\n",
      "963:\tlearn: 0.6618550\ttotal: 3.62s\tremaining: 135ms\n",
      "964:\tlearn: 0.6617666\ttotal: 3.63s\tremaining: 131ms\n",
      "965:\tlearn: 0.6616924\ttotal: 3.63s\tremaining: 128ms\n",
      "966:\tlearn: 0.6615967\ttotal: 3.63s\tremaining: 124ms\n",
      "967:\tlearn: 0.6614931\ttotal: 3.64s\tremaining: 120ms\n",
      "968:\tlearn: 0.6613880\ttotal: 3.64s\tremaining: 116ms\n",
      "969:\tlearn: 0.6613003\ttotal: 3.64s\tremaining: 113ms\n",
      "970:\tlearn: 0.6611873\ttotal: 3.65s\tremaining: 109ms\n",
      "971:\tlearn: 0.6610691\ttotal: 3.65s\tremaining: 105ms\n",
      "972:\tlearn: 0.6609604\ttotal: 3.65s\tremaining: 101ms\n",
      "973:\tlearn: 0.6608435\ttotal: 3.66s\tremaining: 97.7ms\n",
      "974:\tlearn: 0.6607883\ttotal: 3.66s\tremaining: 93.9ms\n",
      "975:\tlearn: 0.6607072\ttotal: 3.67s\tremaining: 90.2ms\n",
      "976:\tlearn: 0.6606167\ttotal: 3.67s\tremaining: 86.4ms\n",
      "977:\tlearn: 0.6605407\ttotal: 3.67s\tremaining: 82.6ms\n",
      "978:\tlearn: 0.6604673\ttotal: 3.68s\tremaining: 78.9ms\n",
      "979:\tlearn: 0.6603832\ttotal: 3.68s\tremaining: 75.1ms\n",
      "980:\tlearn: 0.6602848\ttotal: 3.69s\tremaining: 71.4ms\n",
      "981:\tlearn: 0.6602370\ttotal: 3.69s\tremaining: 67.6ms\n",
      "982:\tlearn: 0.6601307\ttotal: 3.69s\tremaining: 63.9ms\n",
      "983:\tlearn: 0.6600437\ttotal: 3.7s\tremaining: 60.1ms\n",
      "984:\tlearn: 0.6599388\ttotal: 3.7s\tremaining: 56.4ms\n",
      "985:\tlearn: 0.6598257\ttotal: 3.7s\tremaining: 52.6ms\n",
      "986:\tlearn: 0.6597276\ttotal: 3.71s\tremaining: 48.8ms\n",
      "987:\tlearn: 0.6596636\ttotal: 3.71s\tremaining: 45.1ms\n",
      "988:\tlearn: 0.6595779\ttotal: 3.72s\tremaining: 41.3ms\n",
      "989:\tlearn: 0.6594509\ttotal: 3.72s\tremaining: 37.6ms\n",
      "990:\tlearn: 0.6594077\ttotal: 3.72s\tremaining: 33.8ms\n",
      "991:\tlearn: 0.6593470\ttotal: 3.73s\tremaining: 30.1ms\n",
      "992:\tlearn: 0.6592565\ttotal: 3.73s\tremaining: 26.3ms\n",
      "993:\tlearn: 0.6591329\ttotal: 3.74s\tremaining: 22.6ms\n",
      "994:\tlearn: 0.6590211\ttotal: 3.74s\tremaining: 18.8ms\n",
      "995:\tlearn: 0.6589305\ttotal: 3.74s\tremaining: 15ms\n",
      "996:\tlearn: 0.6588383\ttotal: 3.75s\tremaining: 11.3ms\n",
      "997:\tlearn: 0.6587822\ttotal: 3.75s\tremaining: 7.52ms\n",
      "998:\tlearn: 0.6586674\ttotal: 3.75s\tremaining: 3.76ms\n",
      "999:\tlearn: 0.6585844\ttotal: 3.76s\tremaining: 0us\n",
      "Evaluating CatBoost model...\n",
      "Train RMSE:0.6585843889508093\n",
      "RMSE':0.7737347847443783\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69      7516\n",
      "           1       0.95      0.36      0.53     10027\n",
      "\n",
      "    accuracy                           0.63     17543\n",
      "   macro avg       0.74      0.67      0.61     17543\n",
      "weighted avg       0.77      0.63      0.60     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64      1033\n",
      "           1       0.84      0.29      0.43      1405\n",
      "\n",
      "    accuracy                           0.56      2438\n",
      "   macro avg       0.67      0.61      0.53      2438\n",
      "weighted avg       0.69      0.56      0.52      2438\n",
      "\n",
      "precision@10 of train:  0.35050966608084344\n",
      "recall@10 of train:  0.948435764894927\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9326530612244897\n",
      "recall@10 of train 0.32812907799326285\n",
      "precision@10 of test:  0.6116279069767442\n",
      "recall@10 of test:  0.6285041618041173\n",
      "Training DecisionTree model...\n",
      "Evaluating DecisionTree model...\n",
      "Train RMSE:0.08726180789172724\n",
      "RMSE':1.0819217892243225\n",
      "train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7516\n",
      "           1       1.00      0.99      1.00     10027\n",
      "\n",
      "    accuracy                           0.99     17543\n",
      "   macro avg       0.99      1.00      0.99     17543\n",
      "weighted avg       0.99      0.99      0.99     17543\n",
      "\n",
      "test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59      1033\n",
      "           1       0.70      0.66      0.68      1405\n",
      "\n",
      "    accuracy                           0.64      2438\n",
      "   macro avg       0.63      0.64      0.63      2438\n",
      "weighted avg       0.64      0.64      0.64      2438\n",
      "\n",
      "precision@10 of train:  0.35100175746924417\n",
      "recall@10 of train:  0.9489748742916815\n",
      "precision@10 of test:  0.13938356164383595\n",
      "recall@10 of test:  0.839041095890411\n",
      "PERSONAL PRECISION RECALL\n",
      "precision@10 of train 0.9510204081632654\n",
      "recall@10 of train 0.33362503972571933\n",
      "precision@10 of test:  0.5441860465116278\n",
      "recall@10 of test:  0.5959239696719706\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    model.fit(train_x, train_y)\n",
    "    print(f\"Evaluating {model_name} model...\")\n",
    "    test_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
